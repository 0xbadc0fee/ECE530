#+TITLE: ECE530 Lecture Notes
* Module 1
** Overview
+ Categorize the cloud services
+ Purpose on how the cloud is used today
** Section 1_1
*** Notes:
+ 1.1.1 Intro
  + ...how its used today
  + development of I/O systems
  + history of the infrastructure
  + using computers we don't own through infrastructure.
+ 1.1.2 Utility
  + utility infrastructure model, contrast to trad... trad requires forecast of use and growth.
  + old way, over buy in anticipation of growth, leaves gaps in utilization / demand
  + demand is not linear, goes up and down... leave surpluses, expensive surpluses, also create deficits
  + cloud computing is designed from scratch to scale up and down accourding to infrastructure demand
+ 1.1.3 From Mainframes to IoT
  + Mainframes + Terminals ...
  + PC's , 1980's, users have their own systems...
  + Networked PCs, centralized storage system, adding security..
  + 1990s-2000s web revolution, web applications, google, facebook, web servers /services
  + Scalar expansion of web, becoming very complicated,
  + Internet of Things, giving internet to every device, all over the world, wireless sensors, embedded devices
+ 1.1.4 Datacenters and Supercomputers
  + Datacenters
    + Explosion of web size == need large facilities for networked computers / servers
    + very 'fixed' to locations, can't easily relocated datacenters
    + ... Mega Datacenters, lot's of HVAC, physical accomodation for power / heat /emissions etc.
    + need lots of $$, power (1.5% of all USA electricity in 2007), land, skills, etc.
    + really onlcy practical for a few very, very large companies...
  + Supercomputers
    + collective computing, exceeding that of other built systems
    + high processing capability
    + high data handling cap
    + unique ability to solve certain computational challenges
    + require complex scheduling systems
    + requires advanced / complex networking / fibre / etc
    + fastes is anhe-2 (china), very elegant MareNostrom (Spain)
  + 1.1.5 CyberInfrastructure
    + High performance computing
      + when you have application that exceed the capabilities of desktops
      + includes: supercomputers, cluster computers, distributed comp, grid comp, exotic hardware (FPGA, etc)
      + Grid Computing:
        + HPC built as geogrphicall distributed system from collection of comp, net, storage all via h/s network
      + Cyberinfrastructure
        + kewords: DISCOVERY, COLLABORATION
        + comprised of instruments, sensors, HPC systems, data storage systems, visualization facilities, all networked via h/s
        + Layers: 0=base, 1=middleware(net, OS), 2=services, 3=applications... CyberInfrastructure lives in the middle 2
    + CLOUD COMPUTER != CYBERINFRASTRUCTURE, but is "part of" cyberinfrastructure, 
*** DONE Watch lectures
*** DONE Quiz 1.1 (100pts)
** Section 1_2
*** Notes:
+ 1.2.1 Benefits of Cloud Computing
  + Outsource Datacenter
    + economies of scale
    + now afford special skills
    + dev can concentrate on core comp's
    + shorter lead times
    + lower capital expenditures
    + compute power becomes utility commodity like electricity / gas
  + Benefits cont.
    + Reduced capital and operating costs
      + can start small and grow, pay-as-you-go / pay-as-you-grow
    + Simplified app deployment and management
      + common programming model across mobile, browser client, server, cloud
      + access to strong ecosystem of resources
      + integration with existing IT
      + vendors handle new tech & integration
  + Considerations as a Cloud Engineer:
    + Your instances WILL DIE
    + You will share resources
    + the archictecture WILL CHANGE
    + you will never see the lights
  + DO NOT TRUST THE CLOUD
    + you must assume that any failure that can happen in the cloud will happen
+ 1.2.2 Common Cloud Vendors
  + Amazon Web Services AWS (since 2006)
    + Provide:
      + different types of services
      + migration tools
      + analytics
      + mobile services
    + Services
      + mobile services
      + machine learning
      + networking
      + security
      + hosting
    + Scope
      + covers 190 countries across world
      + globally located data centers
      + high reliability, scalable, low-cost infrastructure, high adoption rate
    + History
      + 2003 B. Black / C. Pinkman paper, aws infrastructure
      + 2004 simple queue service launched
      + 2007 over 180000 dev's using platform
      + 2010 all of amazon.com moved to aws
      + 2011 some major outages suffered, EBS problems
      + 2012 first 'Re-Invent' Conference
      + 2020 commitment to 100% renewable energy
  + Goolge Cloud
    + Provides
      + Compute
      + Storage
      + Big Data
      + Machine Learning
    + Comparison
      + slower to roll out services but more mature when rolled out
      + not as many total services as AWS
    + History
      + 2008 google app engine announced
      + 2010 google cloud storage launched
      + 2012 google compute engine launched
  + Microsoft Azure
    + Provides
      + Platform as a service
      + Infrastrucutre as a service
      + Datacenter Infrastructure
    + Comparison
      + not as many services but very very mature and stable
    + History
      + 2008 annouced windows azure platform
      + 2010 azure commercially available
      + 2014 outage affecting major websited including MSN.com
+ 1.2.3 What if Cloud Dies (i.e. vendor pulls the plug)
  + Consider retaining as much in-house capacity as you need to stay alive, disaster plan
  + maintain accessibility outstide of cloude / networking infrastructure / bandwidth capacity / etc.
  + Ultra-Sensitive Data
    + data you can't trust ANYWHERE else
    + can't use external cloud but maybe internal cloud...
    + flag your data, go ahead and host low security on cloud, but know what is high and what is low security
  + Legal aspects
    + Law requires certain data be handled certain ways
    + location based: can data be hosted in a different countries datacenter? JURISDICTIONS
    + content based: health data, financial data, educational data, PII data, etc
    + Don't rely on LAW to be STATE OF THE ART, LAW is REACTIVE and slow, not PROACTIVE.  THINK AHEAD OF THE LAW.
  + Cloud availability issues
    + what assurance that your provider will have enough resources?
    + how bad of damage if you can't scale up quickly when you needed to (burst situations)?
    + what remedies if their services fail and cause you damage? (damages covered in SLA, service level agreement)
    + Amazon approach... SPOT MARKET vs GENERAL MARKET, different pricing based on level of assurances
*** DONE Watch Lectures
** Section 1_3
*** Notes:
+ 1.3.1 What is the Cloud (3 part definition)
  + Cloud Characteristics
    + Common characteristics
      + massive scale, homgenentiy, virtualization, low cost sftwar, resilient computing
      + geographic distr, service orientation, advanced security..
    + Essential characteristics
      + On demand self services
      + broad network access
      + rapid elasticity
      + resource pooling
      + measured service
    + NIST Cloud Computing Model, see slide
      + Models vary by how much you manage vs how much vendor manages
  + Service Models
    + On-prem (private) / You manage all..
    + IaaS / you manage apps - dbases
    + PaaS / you manage apps
    + SaaS / everything managed by vendor (tenant cloud, edge impulse, etc)
  + Deployment Models
    + Public
    + Private
    + Community
    + Hybrid
+ 1.3.2 Deployment Models
  + Public
    + Used by many other entities other than your company
    + hosted off prem
  + Private
    + used only by you
    + hosted on prem
    + full control
    + can have at same time as a public, not mutually exclusive.
  + Hybird
    + Some combination of Public / Private, sharing some data, some functions, some storage
  + 4 Deployment models
    + Enterprize -> Cloud
    + Private Cloud within Enterprise, resources accessed via INTRANET / LOCAL net
    + Community Cloud, INTRANET and INTERNET (VPN), linking clouds together securely
    + Hybrid Cloud, mixing public and private enterprise, intranet and internet, , more complicated.
      + orchestration systems like Kubernets allows to deploy across hybrid, mixed, setups
  + Rationale
    + Private Cloud
      + data security
      + avoid vendor lock-in
      + SLA performance, reliability
      + cost savings.  sometimes it's cheaper to roll your own, especially if data secrecy is an issue
    + Enterprise level considerations when going cloud..
      + CPU/HR , GB/day, ongoing costs
      + hidden costs, mangement, training, onboarding, etc.
      + different cloud models required for different applications
  + Deployment Summary
    + Clouds (how it's structured / built )
      + Private
      + Public
      + Hybrid
    + Services (what it does)
      + IaaS
      + PaaS
      + SaaS
    + Users (how they interact with it)
      + Dashboards
      + Browsers
      + IoT Devices
  + SaaS Maturity Model
    + L1: Ad-Hoc / Custom / Single instance per customer "single tenant"
    + L2: Configurable per customer
    + L3: Configurable and multi-tenant
    + L4: Scalable, Configurable, multi-tenant // load balancer between tenant and infrastructure
  + SaaS Defined
    + model of software deployment where application is hosted as a service provided to customers across the internet
    + alleviates burden of software maint / support BUT users relinquish control over version and customization
+ 1.3.3 Virtualization & Virtual Machines
  + Virtualization
    + you can't physically touch the cloud machines, hardware can and will frequently change
    + to avoid dependency on specific hardware, write programs for virtual machines from the start
      + level 5  Cloud Applications
      + level 4  Cloud Services
      + level 3  Operating System
      + level 2  Virtual Machine Manager
      + level 1  Hardware / Physical
+ 1.3.4 Opportunities and Challenge
  + Benefits
    + Use high-scale / low-cost providers
    + anytime/place access via web
    + rapid scalability up or down and load balancing
    + no on prem IT staff to hire
  + Risks
    + Performance, reliablity, SLA structure
    + control of data, service parameters
    + application features / customization
    + interaction between cloud providers
    + non standar API - mix of SOAP and REST
    + privacy, security, trust..
    + some think the return to supercomputer is opposite of what pc's gave us, freedom from mainframe
    + high integration means high dependency
    + monopolies
+ 1.3.5 Advantages (Detailed)
  + Lower computer costs
    + less power, less compute required
    + since apps run on cloud, less local storage req'd
    + PC itself can be less expensive, thin client
    + PC needs fewer peripherals, cd's, dvd's, etc.
  + Improved Performance
    + fewer large programs running on PC, fewer resources consumed, pc is "faster" or at least less occupied
    + fewer memory processes, services running, thing boot up faster and run more smoothly
  + Reduced Software Costs
    + fewer expensive software purchases per device
    + usually have access to suite of tools would otherwise need to purchase separately (g-suite, o365, etc)
  + Instant Software Updates
    + No longer responsible for patching yourself
    + updates scheduled automatically
    + when access via web client, always getting the latest version
  + Improved document format compatibility
    + everything using standardized extensions, file formats, etc (.docx, .pdf, .csv, etc)
    + if everyone sharing doc's through same cloud, should never be a format or versioning conflict.
  + Unlimited Storage Capacity
    + Cloud computing == virtually unlimited storage
    + PC 1TB is tiny compared to cloud storage
  + Increased Data Reliability
    + If one node goes down, data is still safe
    + Cloud acts like a data safe, archive
  + Universal Document Access
    + no problem with cloud because not taking documents with you
    + docs live and remain in cloud, you access and edit them as you need through a portal
    + docs are instantly available regardless of where you are.
  + Latest Version Available
    + No complicated migrations / upgrades / conversions
    + Cloud always has latest version of docs and apps both
  + Easier Group Collaboration (remember SharePoint :(  )
    + Sharing docs easily and reliably == more collaboration
    + can allow many users access to few docs with out fear of issues
    + multiple users can collaborate on multiple projects all at same time
  + Device Independent
    + agnostic, no pref Mac, Win, Linx, etc
    + hardware agnostic, no pref pc, thin client, desktop, etc
+ 1.3.6 Disadvantages (Detailed)
  + Always on Internet Connection
    + cloud compute impossible w/o reliable connection
    + internet used both for applications and documents.  I.E. MS-Word and Documents / Excel and Spreadsheets / etc.
    + dead internet == no work being produced
  + Poor performance if low-speed connections
  + Features might be limited
    + fewer options with cloud Word vs Office Word, etc
  + Can be slow
    + constantly handling files, back and forth between client and server, etc
  + Stored data may not be secure
  + Stored data can be lost
    + need some kind of phys backup
  + HPC Systems
    + not clear you can run heavy software from cloud
    + Scheduling resources
  + General Concers
    + Each cloud vendor using different protocols / different API's
    + i.e. amazon created it's on DB system (not SQL)
*** DONE Watch Lectures
*** DONE Quiz 1.3 (100pts)
** Section 1_4
*** Notes:
+ 1.4.1
  + IaaS: OpenStack
    + Open source cloud computing platform
    + Infrastructure as a service solution
    + Many independent services
  + Quick Facts:
    + joint project by rackspace and NASA
    + launched in 2010, now community of 15,000 people in 136 countries
    + OpenStack 1 million+ lines of code in Python
  + Community Support
    + over 200 companies helping
  + High level architecture
    + [[https://access.redhat.com/webassets/avalon/d/Red_Hat_OpenStack_Platform-11-Architecture_Guide-en-US/images/fce6394275bd3444892c5d3a91ccf17c/RHEL_OSP_arch_347192_1015_JCS_01_Interface-Overview.png][Overview]]
      + Dashboard is launch point, provides UI to:
        + network, storage, compute, identity, image, object storage.
+ 1.4.2
  + OpenStack Services
    + _Compute: NOVA_
      + on demand networked virtual machines
      + KVM & Xen available choices for hypervisors or linux container like Docker
    + _Network: NEUTRON_
      + allowing users to create their own networks and then attach interfaces to them
      + highly configurable
      + legacy networksing: nova-network
        + simplicity
        + lack functionality like VPN, load balancing, firewall. (EDIT, it now has these abilities)
    + _Block Storage: CINDER_
      + provides persistent block level storage devices for openstack instances
      + manages the creation attaching and detaching of the block devices to servers
    + _Objecst Storage: SWIFT_
      + accepts files to upload, modifications to metadata, mods to container creation
      + swift architectre is very distributed, no single point of failure, scales horizontally
    + _Identity: Keystone_ (difficult to configure, easy to lock yourself out)
      + provides single point of integration for OpenStack polic, catalog, token, and uthentication.  like group policy object
      + supports multiple forms of authenticaiotn including standard usernameand password credentials, token-based systems and AWS-style.
      + User.Tenant.Role.
    + _Image Storage: GLANCE_
      + provides discovery, registration, and delivery services for disk image servers
      + can also be used to store and catalog unlimited number of backups
    + _Dashboard: HORIZON_
      + Bringing together all of the above for user access UI
      + provides administrators graphical interface for access, provisioning, automation.
    + _Compared to AWS_

| Service | OpenStack | AWS|
|---------|:--------:|-----|
|compute   | Nova    | EC2 |
|Network   | Neutron | VPC |
|Blk Strge | Cinder  | EBS |
|Obj Strge | Swift   | S3  |
|Img Mgmt  | Glance  | AMI |
|Dashboard | Horizon | Console|
|Identity  | Keyston | IAM |
 
*** DONE Watch Lectures
CLOSED: [2023-04-18 Tue 14:37]
*** DONE Homework 1: IaaS Infrastructure (140pts) [8/8]
CLOSED: [2023-04-10 Mon 22:38]
- [X] Keystone [4/4]
  - [X] Generate Token
  - [X] Generate demo and admin users
  - [X] Retrieve User list
  - [X] Retrieve role list
- [X] Glance [2/2]
  - [X] import cirros OS image
  - [X] retrieve image list
- [X] Nova [3/3]
  - [X] retrieve VM list
  - [X] create VM
  - [X] login to VM
- [X] Neutron [1/1]
  - [X] create a network
- [X] Horizon [2/2]
  - [X] login with proper account
  - [X] retrieve service info
- [X] Cinder [2/2]
  - [X] create a volume
  - [X] retrieve volume list
- [X] Swift [2/2]
  - [X] create a container
  - [X] upload and download files
- [X] Extra Points [4/4]
  - [X] create a VM with public network connected
  - [X] import and create a vm with ubuntu image inside openstack
  - [X] attach volume to VM
  - [X] install one extra service (Ceilometer, Heat, etc)
* Module 2
** Overview
** Section 2_1
*** DONE 2_1_1 AWS Intro
CLOSED: [2023-04-17 Mon 13:37]
- AWS Biz:
  subsidiary of amazon, pay as you go, cloud on demand, launched in 2002
- server farms throughout the world
- @2020, 212 services
- 2017, dominant 34% of cloud
- Collection of remote compute services...
- Compute:
  - Elastic Compute EC2
  - Elastic MapReduce (EMR), hadoop on EC2
- Storage
  - Simple Storage Service (S3) - storage
  - Glaciaer = low cost long term storage (high redundancy, low access time)
  - Elastic Block Storage (EBS) - persistent block storage
- Database
  - DynamoDB = NoSQL backed by SSD
  - ElasticCache = in-memory cache based Memcached
  - Relational databse services (RDS) = MySQL, Postgres, Aurora w/ MySQL
- Platform Model:
  - | Deployment & Admin |
  - | App Services
  - | Compute | Storage | Database |
  - | Networking |
  - | AWS Global Infrastructure |
*** DONE 2_1_2 AWS Infrastructure
CLOSED: [2023-04-17 Mon 09:37]
- World wide, divided into regions, i.e. Europe, SA, US, etc
- Availability 'Zones'
- Region = geographic area.  Regions have multiple 'locations', 11 regions.
- Each region has 2 availability zones, distinct data centers
- Each EC2 region isolated from each other
- failover and fault tolerance built into the cloud already, all we have to do is build our applications.
- Edge Locations
  - 52 edge locations
  - Edge locations are CDN edge poitns
    - more edge locations than regions
  - Used to cache data physically close to the user
- Global infrastructure
  - 
*** DONE 2_1_3 AWS Networking
CLOSED: [2023-04-17 Mon 11:40]
- Domain Name System, port 53, HA & Scalable DNS
- 'Router 53' is the name of the AWS service
- VLAN: AWS Direct connect uses vlan. 802.1q
  - dedicated connection, multiple vitural nic
- client can use same conenctio for private and public management traffice
- AWS Direct Connect:  High Throughput dedicated, 10gb/s,
- VPC Virtual Private Cloud: provisionally logically isolated section of aws cloud wehre you can launch aws resources in a virtual network that you define.
- i.e. create a public store front, publice facing subnet for webservers
*** DONE 2_1_4 AWS EC2 & EBS
CLOSED: [2023-04-17 Mon 12:40]
- EC2 Elastic Compute (re: Nova)
  - reconfigurable capacity
  - provision virtual instances (os's)
  - marketplace for pre-configured instances
  - uses Xen virtualization (Xen = hypervizor)
  - Elastic load balancing done automatically
    - scaling based on demand
    - min and max instance thresholds
    - triggers for scaling in and scaling out
    - uses metrics collected by aws ~cloudwatch~
    - free 
- EBS Elastic Block Storage (re: Cinder)
  - Data.  Datastores, content networks, databases, all the assests your web apps need to either store or present over the web.
  - Mount specific BLOCK devices (i.e. sda1, sdh, sdb, etc) logical drives.
  - BLOCKS available (like vmware datastores) to multip vm's from variety of use scenarios.
  - can be up to 1TB ea
  - EBS built on replicated storage so if one phys device goes down, can failover to another.
  - EC2 handles INSTANCES / EBS handles STORAGE
*** DONE 2_1_5 Google Cloud
CLOSED: [2023-04-18 Tue 12:40]
- GCP Google Cloud Platform
- infrastrucutre services; Google Search, Gmail, YouTube all sparked the GCP growth
- IaaS, PaaS, and serverless computing environments
- 1st, need datacenters.  Distributed world wide.  Low latency
- 600 services
- divided by types; Ingest, Storage, Process / Analyze, Explore & Viz
- Market share, GCP growing but still a fraction of AWS
*** DONE 2_1_6 MS Azure
CLOSED: [2023-04-18 Tue 13:38]
- MS AZURE, (formerly WINDOWS AZURE)
- same IaaS / Paas model
- somewhat specialized to MS products (office)
- Big differ between AWS and Azure is 6-8yr head start with AWS
- Azure has lots of datacenters, some specifically USGOV
- 54 Regions around globe, increasing ea year (54 @ 2018)
- 1 Azure GEOGRAPHY has multiple REGIONS
- Stack:
  - App Services
  - Software Services
  - Platform Services (SQL | .NET | Live | Share-Point | CRM)
  - Infrastructure Services
- Details of AZURE LAYER
  - specialized OS called Microsoft Azure, runs "fabric layer"
  - manages compute and storage resource clusters within MS datacenters that it then presents to the application layer running on top of Azure Layer
  - Described as a "cloud layer" running on top of a number of Windows Server systems (Windows server 2008), optimized for Hyper-V hypervisors.
- Design of AZURE
  - Scaling of compute and storage controlled by "fabric" layer
  - Also provides management (i.e. Keystone & Nova)
- Benefits of AZURE
  - easy for windows users / offices
  - active directory, sharepoint, O365, etc
  - less overhead for IT staff
- .. vs GCP
  - GCP stronger in ML, big data, container support
- .. vs AWS
  - AWS hyper generalized, open standards, everything to everyone
- Overall cloud biz
  - 2018 200 billion, 2022 340 billion, ...
- No public data avail on how big AZURE really is
- Amazon specifies AWS revenue, MS only reports Azure growth rate (2019 62%, 2018 78%) over previous (compound ?)
*** DONE Quiz 2_1
CLOSED: [2023-04-18 Tue 13:45]
** Section 2_2
*** DONE 2_2_1 Cloude Edge
CLOSED: [2023-04-18 Tue 13:55]
- Clients talk to clouds via web browsers & standards
  - just the outer 'skin' of it though
  - much more going on underneath, can host entire businesses end to end
- Big Picture..
  - Client req handled by first tier layer, PHP, ASP etc
  - these are light services, very fast, nimble
  - first tier caches info (ssl, keys, etc) for use in second tier)
  - second tier is called 'shards'
- Many styles of 'cloud' system
  - at the edge, cloud is taylored for vast # of clients and quick response
  - further inside, taylored to high volume services that run pipeline of info
  - deepest inside, world of virtual computer clusters, scheduled with each other, being controlled and scheduled by mapreduce...
- Outer Tiers: replication is KEY
  - replicate PROCESSING
  - replciate DATA
  - replicate CONTROL INFORMATION (keys, ssl, managment info)

*** DONE 2_2_2 Sharding
CLOSED: [2023-04-18 Tue 14:25]
- Sharding happens at TIER 2
- This is where caching first takes place (last search, ssl keys, cookies)
- Sharding is a method for allocating data items to nodes of a distributed caching or storage system based on the result of a hash function computed on the item identifier. It is ubiquitously used in key-value stores, CDNs and many other applications.
- Caching in tier 2 is what makes tier 1 work
  - ..always use cached data when possible
  - ..replicate data within cache to spread load
  - ..not everything needs to be fully replicated, so we use 'shards' with just a few replicas
  - ..uses key value pairing to securely link caches to their users, destinations, services, etc.
- Sharding is readlly HORIZONTAL scaling.  SPREADING the ability to ACCESS the cloud across mulitple instances.
- HOW? database table example.  Like breaking down 10,000 row database into smaller tables, with also smaller indecies, and running them in parallel across more instances.  Same singular table data, but all runs and accesses faster while also having some built in fault toleration.  (1 table going down won't take out whole database)
- Smaller indexes = = faster queries = = faster applications
- Example Cache services (kw DISTRIBUTED HASH TABLE):
  - Memcached / Redis
    - in-memory key-value stored chuncks of arbitrary data
  - Dynamo
    - service created by amazon
  - BigTable
  - IBM WebSphere eXtreme Scale
- Necesasry to ALWAYS shard data?
  - YES.  if almost every external request is going to use it anyway, YES DO SHARD
  - understands patterns of access to the cloud data /services you manage
- UPDATING REPLICAS
  - So yo uhave replicas now, of course you need to sync / update them right
  - also happens according to 'patterns' of access
  - some can be singular updated, others must be done across parallel machines running concurently
  - term sharding is for data, but might talk about 'parallel computation on a shard'
  - 
*** DONE 2_2_3 Critical Path
CLOSED: [2023-04-18 Tue 14:30]
- Critical path.. notion of what is important in a querie / request..
- what actions contribute to any percievable delay between the user's request and the response to their request.
- What if a request triggers and update
  - if updated done asynchronously, user might not notice on their end..
    - often work this way
    - avoids waiting for slow services to prcess the updat but may force their tier-one services to 'guess' outcomes
  - Many cloud systems use these sort of tricks to speed response times
- Tier 1 PARALLELISM
  - parallelism speeds up first tier services
  - asks itself, will it be faster...
    - for x to just compute response
    - or for x to subdivide work by spreading it out over subservices
  - ~Werner Vogels~ (amazon) commented that amazon pages have content from 50 or more parallel sub services that ran, in real time, your request!
  - networks, data centers, infrastructure can all faile along the way adn create inconsistencies..
*** DONE Quiz 2_2
CLOSED: [2023-04-18 Tue 14:39]
* Module 3
** Overview
- Concepts:
  - CAP Theorem
  - Failure Modes
  - Stronge and Eventual Consistency
  - Partitioning Algorithms
** Section 3_1
*** DONE 3_1_1 CAP Theorem
CLOSED: [2023-04-18 Tue 16:24]
- KW 'Distributed Systems'
- ref Eric Brewer (keynote ACM PODC 2000)
  - Pick 2...
  - Consistency, Availability, Partition Tolerance
  - only possible to get 2/3
    - Consistency: all nodes see same data at same time
    - Availability: every req gets a reply
    - Partition Tolerance: system continuse to operate despite arbitrary message loss / failure of parts / fracture
- Interactions with Web Services
  - operations commit or fail in entirety (ATOMIC)
  - committed transaction are visible to all future trx (CONSISTENT)
  - un-commited trx isolated from each other (ISOLATED) like git
  - once commited, trx is permament (DURABLE)
- Consistency: Atomic Data Object
  - total order on all operations such that each operation looks as if it were complete at a single instance
  - equivalent to requiring req's if the distributed memory to act as if they were executing in a single node, responding to operations one at a time.
  - Atomic read/write shared memory
    - any read operation that begins after a write operation completes must return THAT value, or the result of a later write operation
- Consistency: What does it mean?
  - re CAP Theorem means 2 things;
    1. That update to same data item are applied in some agreed-upon order
    2. that onece an update is achnowledged to an external user, it won't be forgotten.
  - Not all systems need both properties
- Consistency: Risks (also inconsistencies)
  - inconsistency causes bugs
    - client can't trust the servers...
  - Weak or Best Effort consistency...
    - strong security guarantees DEMAND consistency
    - would user trust medical health data to system with weak consistency?
- ACID to BASE
  - ACID
    - [A]tomic:  all trx succeeds, or roll back pre trx
    - [C]onsistent: can't leave incompleted
    - [I]solated: can't interfere / contradict each other
    - [D]urable: completed trx's persist, even when servers reboot.
  - 
*** DONE 3_1_2 CAP Theorem Examples
CLOSED: [2023-04-18 Tue 16:24]
- Book Store / Shop:
  - to keep inv accurate, maybe you lock database once trx starts so that only ever the actual inventory is displayed in web..
  - ... only works in small scale, consider larger example, like amazon.
  - if big, maybe you used cached data...
  - if big, maybe consider violating AC[I]D isolation, let transactions contradict each other to an extent...
- Vogels @ Amazon
  - CTO at amazon
  - involved in buiding a new shopping cart service
    - old one used strong consistency for replicated data
    - new one built over DHT distributed hash table (CHORD), weak consistency, but eventual convergence
    - 
*** 3_1_3 CAP Theorem Details
- Consistency: Eventual / Convergence
  - informal guarantee that if no new updates, eventually all accesses to item with return last updated result
  - i.e. BASE:
    - [B]asically
    - [A]vailable
    - [S]oft state
    - [E]ventual consistency
- Core Problem
  - when can we sweep consistency under the rug?
    - if we weaken a safety critical property, bad things can happen...
    - sites like amazon and ebay do OK w/ weak guarantees, model just doesn't demand otherwise...
    - embracing weaker nature, reduces syncronization, better response time
  - but what if applications in question are high-assurance, must be accurate every transaction??
  - [A]vailability (C[A]P):
    - for a distributed system to be condinuously available, every request received by non-failing node must result in a response
    - any algorithm used by the service MUST eventually TERMINATE
    - no BOUNDS on how long algorithm may run before TERMINATING, therefore susceptible to UNBOUNDED computations...
  - [P]artition Tolerance (CA[P]):
    - network allowed to lose messages from one node to another
    - when partitioned messages between nodes in different partitions are lost
    - requirements:
      - atomicity: every response is atomic / even though parts of messages might not be delivered
      - available: every node receiving a request MUST provide a response / even though parts of messages might not be delivered.
      - if system behaves AS IF all nodes were AVAILABLE, then it is considered partiion tolerant
  - Web Services problem:
    - similarly expected to by HIGHLY AVAILABLE (every req gets a resp)
    - when services go down, cause real world problems (finance, healthcare, telecomm, etc)
    - FAULT TOLERANCE:
      - When some nodes crash or some communication links fail, it is important that the services still performa as expected. One desirable fault tolerance property is the ability to survive a network partitioning into mulitiple components..
      - 
*** 3_1_4 CAP Theorem and the Cloud
- Is CAP valid in the CLOUD ??
  - data centers networks don't normally have partition failures...
    - but wide area links do fail...
    - most services design to do updates in single place and mirror read only data to others..
    - so CAP scenario can't really pop up...
  - Brewer's arguments about not waiting for a slow service to respond make sense
    - Argues for using any single replica you can find...
    - but does this preclude that replica being CONSISTENT??
- Properties you might want in the CLOUD
  - CONSISTENCY: updates in specified order
  - DURABILITY: once accepted, not forgotten
  - real-time RESPONSIVENESS: replies within BOUNDED delay
  - SECURITY: only permits AUTHORIZED actions by AUTHORIZED parties
  - PRIVACY: won't discloser personal data
  - FAULT-tolerance: failures can't prevent system from providing desired results
  - COORDINATION: actions won't interfere or contradict each other
- Cloud services and their properties
| Service    | Properties it guarantees                          |
|------------+---------------------------------------------------|
| Memcached  | No special guarantees                             |
| Google GFS | File is current if locked                         |
| BigTable   | Shared key-value pair with consistent properties  |
| Dynamo     | Amazon shopping cart eventual convergence         |
| Databases  | Snapshot isolation                                |
| MapReduce  | functional compute model w/ strong guarantee      |
| Zookeeper  | Yahoo! file system, sophisticated properties      |
| PNUTS      | Yahoo! database, shared data, consistency options |
| Chubby     | locking services, strong guarantees               |

- Conclusions:
  - Notice that services...
    - most of them cost 10's or 100's of MILLIONS to create..
    - huge investment upfront
    - i.e. Oracle has billions invested..
  - CAP isn't about telling ORACLE how to build a database product...
    - CAP is a warning to YOU that strong properties CAN easily lead to SLOW services
    - but thinking in terms of WEAK properties is often SUCCESSFUL strategy that yields good solutions requiring less effort

*** DONE Assignment: CAP Theroem Reading Notes
CLOSED: [2023-04-20 Thu 10:56]
1. [X] Spanner, TrueTime & CAP ...
   1. Read & Review
2. [X] CAP 12 years later...
   1. Read & Review
3. [X] Submit summary
** Section 3_2
*** DONE 3_2_1 [C]onsistency
CLOSED: [2023-04-20 Thu 13:45]
- Tiers:
  clouds have tiers, levels.
  - tier 1: lightweight, responsive, web based, also route or handle some services
  - tier 2: key value pair. stores / caches credentials and authorizations.
  - tier (inner): online services that handle requests not handled in the first tier.  persistent files, transactional services, shielded from load though.
  - tier (backend): running offline services, indexing web overnight, updates, scheduled loads, 
- Replication:
  - core feature of cloud
  - to handle more work, make more copies
  - if load increases, make more copies...
  - if load decreases, kill redundant duplicates...
  - load balancing: spread requests over the duplicated nodes
- Things we can replicate in the cloud:
  - Files / Storage
    - compare "write once" data (images, photos) to evolving data (spreadsheets, inventory, logs, etc)
  - Computation
    - replicate a single request and distribute it across the duplicated nodes to share comp load
  - not just FASTER, also more FAULT TOLERANT
- Things to "MAP" in REPLICATION
  - data
  - fault tolerant req processing
  - coordination and syncronization
  - parameters & configuration data
  - security keys and credentials
  - user / group / membership information (like AD, GPO)
- ..back to CONSISTENCY
  - want REPLICATED data to behave in CONSISTENT manner
  - an INCONSISTENT service appears as BROKEN
  - DIFFICULT CHALLENGE, how to get many copies to act like just one??
- IMPLEMENTATION
  - need a 'reference' system, some kind of MASTER copy
- DANGERS of INCONSISTENCY
  - lack of TRUST
  - when to trust "weak" or "best effort" consistency?
  - 
*** DONE 3_2_2 Distributed Systems
CLOSED: [2023-04-20 Thu 13:46]
- Definition:
  A collection of automata whose distribution is transparent to the user so that the system appears as one local machine.  This is in contrast to a network, where the user is AWARE that there are several machines, and their location, storage, replication, load balancing, and functionality is not transparent.  DISTRIBUTED systems usually use some kind of client-server organization.
- Definition cont:
  [Andrew Tanenbaum] a distributed system is a collection of independent computers that appear to the suers of the system as a single computers
- Definition cont:
  [Michael Schroder] a distributed system is several computers doing something together.  Thus, a distributed system has three primary characteristics: multiple computers, interconnections, and shared state.
- Basic building blocks:
  - RPC, remote procedure calls
  - DO, distributed objects
- Distributed Services
  - 2PC/3PC and Paxos
  - REPLICATION control
- Cloud Computing
  - Gossiping
  - key-value pair / nosql stores / caches / credentials
  - stream processing (DATA in TRANSIT)
- Legacy Layers (old but still important)
  - Distributed File Systems
  - Distributed Shared Inventory
  - Self Stabilization
- Very IMPORTANT..
  - Security and BYZANTINE FAULT-TOLERANCE
- High level GOALS of DISTRIBUTED systems:
  - Heterogeneity: varried services, but with same guarantees
  - Robustness: fault-tolerant
  - Availability: of data & operations despite failures / network partitions
  - Transparency: 
  - Concurrency: support many clients
  - Efficiency: fast ops, reads, & writes
  - Scalability: many ops per second despite thousand of services / millions of users
  - Security: system should be protected from attackers and bugs
  - Openness: each system built on top of other services/potocols, layered stack architecture
- Some intricacies of DISTRIBUTED systems
  - Syncronization: multiple clocks, difficult to agree on exact time
  - Concurrency: multiple SIMULTANEOUS accesses potential to CONFLICT
  - Failures: High probability (guarantee?) of failures, many moving parts.
  - Consensus: difficult to reach consensus, lack of synchronization, who has best latest copy  of data?
- different DISTRIBUTED system MODELS, CURRENT
  - Client/Server
  - Multi-tier
  - Peer-to-Peer
  - Agent based system
  - Mobile CODE
  - Service-orientec computing
  - Cloud Computing
- EMERGING DISTRIBUTED system MODELS
  - Cloud, Edge, Beneath the Cloud
  - 
*** DONE 3_2_3 Two Phase Commit
CLOSED: [2023-04-20 Thu 13:46]
- addressing the [C]onsistency issue:
  - [Leslie Lamport] DON'T USE CLOCKS, clocks contradict each other, who wins?
  - use LOGICAL CLOCKS. i.e. if [B] happens after [A], response to [B] must be at least as current as response to [A]
  - also researched... VECTOR CLOCKS (but not in this material)
- hence 2 PHASE COMMIT
  - a kind of building block for a LOGICAL CLOCK, tied to 'consensus' or 'agreement'
  - TRANSACTION:
    1. assign transaction and ID
    2. GET pending state
       1. updated done at various places visited..
       2. read and update or write lock...
    3. if WRONG, ABORT.
    4. OTHERWISE, request a COMMIT (commit can fail though)
- 
- 
*** DONE QUIZ 3.2
CLOSED: [2023-04-20 Thu 13:46]
** Section 3_3
*** DONE 3_3_1 Byzantine Failures
CLOSED: [2023-04-20 Thu 17:40]
- Failure Detection in a newtwork
  - Many think of SKEEN's 3PC as a practical protocol..
  - but to use it one needs perfect failure detection that never makes mistakes
  - is it even possible to build such a failure detection
- Notions of FAILURE
  - types of failure models?
  - lots of things can go wrong:
    - networks drop packets
    - links break
    - processes fail / hang
    - clock malfunction, go out of sync
    - a machine could freeze up then resume
    - processes can corrupt memory yet not quite crash
    - processes can be hijacked by viruses / malware..
  - EXAMPLE: Byzantine Failure @ Amazon
    - 2008: AWS S3 brought down for several hours.  Single bit hardware error propogated throughout system..
    - http://status.aws.amazon.com/s3-20080720.html
  - REAL systems
    - LINUX and WINDOWS use timers for FAILURE detection
      - can fire even if remote side is healthy
      - possible to get innacurate failure detection, false pos failure
      - using time, many types of failure can be detected
    - Some APP depend on TCP, but TCP also uses timers at it's core and has same problem
  - BYZANTINE failure model
    - much debated..
    - since programs are buggy, always apealing to use such a model.  A bug gives a random corrupt behavior, like a mild attack
    - but BYZANTINE model is hard work with and can be costly (must 'outvote' the bad process)
*** DONE 3_3_2 Examples of Failure Modes
CLOSED: [2023-04-20 Thu 17:40]
- FAILURE MODES (cont)
- Recall, 2PC and 3PC normally used, std in linux & windows, rely on timers to detect failures
  - prone to mistakes, i.e. P thinks L is faulty but L is really fine.
- VOGELS: World wide failure sensing technique
  - VOGELS wrote a paper, argued we could do much better than BYZANTINE
    - cloud managment layer, forces slow nodes to crash and restart...
    - so management layer already a trusted partner more robust than most nodes...
  - 'POSTMAN ALWAYS RINGS TWICE'
    - suppose mailman wants signature, rings bell, waits, no answer, does he assume you DIED?
    - hopefully not...
    - VOGELS suggest multiple reasons machines timeout but are not faulty
- Causes of delay in CLOUD..
  - Scheduling can be sluggish,
  - node might get BURST of messages, temp overflow sockets, triggers message loss,
  - machine might become overloaded, too many vm's,
  - application might run wide, page heavily,
- VOGELS suggestions..
  - ADD some kind of failure monitoring SERVICE as a STANDARD network component,
  - instead of relying on TIMEOUT, even protocols like RPC and TCP would ASK the SERVICE and it would tell them,
  - set it up to do some inquiry, sleuthing first.  ask the OS for info on that machine, check network, etc.,
- Why clouds DON'T do this...
  - in clouds, focus is on keep MAJORITY of system running,
  - not concerned with the WHY or EXCUSE for a failing node, just move on,
  - keeping cloud up as a WHOLE is more valuable than waiting for slow node to catch up,
  - END USER EXPERIENCE IS WHAT MATTERS MOST
  - So, cloud is casual about killing things
  - avoids failure monitoring SERVICES because could become bottlenecks.
- More reasons...
  - most sofware is buggy
    - BOHRBUGS and HEISENBUGS
      - BOHRBUGS: boring and easy to fix
      - HEISENBUGS: seem to hide when troubleshooting, caused by concurrency problems, hard to fix, crashes can seem unrelated to the bug
  - Studies show that BUGS persist throughout LIFETIME of software no matter how mature
  - if something acting strange, maybe it's failing,
- More reasons ...
  - TIMING is flakey
    - at cloud scale, w/ millions of nodes, CANNOT trust TIMING,
    - too many things can cause problems, show up as timing faults or time out incorrectly
*** DONE 3_3_3 Synchronous and Asynchronous Execution
CLOSED: [2023-04-20 Thu 17:51]
- SYNCHRONOUS
  - messages ARRIVE on time,
  - ... PROCESSES share synch clock
  - ... failured detected easily
- ASYNCRHONOUS
  - NONE OF THE ABOVE
- Clouds are NEITHER
  - Designed around ASYNCHRONOUS, but clocks do work most of the time,
  - the systems all have clocks, the SOFTWARE TREATS the system as ASYNCHRONOUS, but in practice we do have access to time.
  - BEGIN as ASYNCHRONOUS, as resources allow, can ENRICH system with some SYNCHRONOUS tools,
- SUMMARY,
  - 3PC in theory is better than 2PC, but world doesn't work perfectly enough for 3PC
  - 3PC more costly, extra communication round, but still blocks / fails
  - failure detection tools could help, but cloud is not a good fit for failure detection services,
  - cloud transactions REQUIRE active, health loggin service.  If it goes down, could transaction subsystem hangs till restart.
  - 
*** TODO 3_3_4 Data Partioning
*** TODO QUIZ 3.3
** Section 3_4
*** TODO 3_4_1
*** TODO 3_4_2
*** TODO 3_4_3
*** TODO 3_4_4
*** TODO 3_4_5
*** TODO Reading Assignment: DYNAMO
** TODO Homework #2
* Module 4
* Module 5
