
# Table of Contents

1.  [Module 1](#orge634e36)
    1.  [Overview](#org7bc53a1)
    2.  [Section 1<sub>1</sub>](#orgcb16d24)
        1.  [Notes:](#org04fec6c)
        2.  [Watch lectures](#org6a96d8b)
        3.  [Quiz 1.1 (100pts)](#org5242877)
    3.  [Section 1<sub>2</sub>](#org3e18ff1)
        1.  [Notes:](#orgbf0c811)
        2.  [Watch Lectures](#orgab7388c)
    4.  [Section 1<sub>3</sub>](#org5ebcd59)
        1.  [Notes:](#orgc72e248)
        2.  [Watch Lectures](#org532203f)
        3.  [Quiz 1.3 (100pts)](#org2c3897e)
    5.  [Section 1<sub>4</sub>](#org6a4efdd)
        1.  [Notes:](#org35af49e)
        2.  [Watch Lectures](#orgc8b61d9)
        3.  [Homework 1: IaaS Infrastructure (140pts) <code>[8/8]</code>](#org9608a7d)
2.  [Module 2](#orga7e61cd)
    1.  [Overview](#orgf3e91da)
    2.  [Section 2<sub>1</sub>](#org9578e47)
        1.  [2<sub>1</sub><sub>1</sub> AWS Intro](#org7e569dc)
        2.  [2<sub>1</sub><sub>2</sub> AWS Infrastructure](#org0c618bb)
        3.  [2<sub>1</sub><sub>3</sub> AWS Networking](#org3978818)
        4.  [2<sub>1</sub><sub>4</sub> AWS EC2 & EBS](#org9ccbe37)
        5.  [2<sub>1</sub><sub>5</sub> Google Cloud](#org2606bc5)
        6.  [2<sub>1</sub><sub>6</sub> MS Azure](#orgb15a681)
        7.  [Quiz 2<sub>1</sub>](#org5cc9656)
    3.  [Section 2<sub>2</sub>](#orge369732)
        1.  [2<sub>2</sub><sub>1</sub> Cloude Edge](#orga160bc7)
        2.  [2<sub>2</sub><sub>2</sub> Sharding](#org4b7fa02)
        3.  [2<sub>2</sub><sub>3</sub> Critical Path](#org5a99d55)
        4.  [Quiz 2<sub>2</sub>](#org48b15d1)
3.  [Module 3](#org6645ff4)
    1.  [Overview](#org385a62b)
    2.  [Section 3<sub>1</sub>](#org7e3e99d)
        1.  [3<sub>1</sub><sub>1</sub> CAP Theorem](#org5196455)
        2.  [3<sub>1</sub><sub>2</sub> CAP Theorem Examples](#org93ffaae)
        3.  [3<sub>1</sub><sub>3</sub> CAP Theorem Details](#org7cb1888)
        4.  [3<sub>1</sub><sub>4</sub> CAP Theorem and the Cloud](#orgeccdfc8)
        5.  [Assignment: CAP Theroem Reading Notes](#org48851b0)
    3.  [Section 3<sub>2</sub>](#orgb55ab2d)
        1.  [3<sub>2</sub><sub>1</sub> [C]onsistency](#org32e848a)
        2.  [3<sub>2</sub><sub>2</sub> Distributed Systems](#org2c19e5d)
        3.  [3<sub>2</sub><sub>3</sub> Two Phase Commit](#org9188fab)
        4.  [QUIZ 3.2](#orgbb24d43)
    4.  [Section 3<sub>3</sub>](#org0a666df)
        1.  [3<sub>3</sub><sub>1</sub> Byzantine Failures](#org6429041)
        2.  [3<sub>3</sub><sub>2</sub> Examples of Failure Modes](#orgdc467e3)
        3.  [3<sub>3</sub><sub>3</sub> Synchronous and Asynchronous Execution](#org0487041)
        4.  [3<sub>3</sub><sub>4</sub> Data Partioning](#org5cae47f)
        5.  [QUIZ 3.3](#orgbdf69d9)
    5.  [Section 3<sub>4</sub>](#orgdfb83bb)
        1.  [3<sub>4</sub><sub>1</sub> Scaling Data Systems on the Cloud](#orgb8e55ec)
        2.  [3<sub>4</sub><sub>2</sub> Eventual Consistency (Examples)](#orgab8631c)
        3.  [3<sub>4</sub><sub>3</sub> Deep Dive on DynamoDB](#orgae9ff3e)
        4.  [3<sub>4</sub><sub>4</sub> Service Level Agreements](#org5090052)
        5.  [3<sub>4</sub><sub>5</sub> Dynamo Partition Algorithm](#org8bd6015)
        6.  [Reading Assignment: DYNAMO](#org0e53aa1)
    6.  [Homework #2](#orga7ed267)
4.  [Module 4](#org22d52fc)
    1.  [Section 4<sub>1</sub>](#orgb36aa3a)
        1.  [4<sub>1</sub><sub>1</sub> SQN and NoSQL](#org3ede6f5)
        2.  [4<sub>1</sub><sub>2</sub> Relational](#org3089007)
        3.  [4<sub>1</sub><sub>3</sub> Non Relational](#org8b7b30f)
        4.  [4<sub>1</sub><sub>4</sub> NoSQL Flavors](#org289d326)
        5.  [4<sub>1</sub><sub>5</sub> NoSQL Data Modeling](#org01dd6f6)
        6.  [Quiz 4<sub>1</sub>](#orge0cacfa)
    2.  [Section 4<sub>2</sub>](#orga48bcc0)
        1.  [4<sub>2</sub><sub>1</sub> Active Cloud Storage](#org3388eb0)
        2.  [4<sub>2</sub><sub>2</sub> Long Term Storage](#org4bcd119)
        3.  [Quiz 4<sub>2</sub>](#org19e6f56)
    3.  [Section 4<sub>3</sub>](#org9a3a90e)
        1.  [4<sub>3</sub><sub>1</sub> Data Pipeline without Messaging System](#org8f74d4d)
        2.  [4<sub>3</sub><sub>2</sub> Data Pipeline with Messaging System](#org56eef89)
        3.  [4<sub>3</sub><sub>3</sub> Amazon SQS](#org37a7bfc)
        4.  [4<sub>3</sub><sub>4</sub> AMQP and Exchanges](#org91aad98)
        5.  [Reading Assignment: Apache Kafka](#orgedcf551)
    4.  [Section 4<sub>4</sub>](#orged740ac)
        1.  [4<sub>4</sub><sub>1</sub> Introduction to Kafka](#org86353d3)
        2.  [4<sub>4</sub><sub>2</sub> Deeper in Kafka](#orgc0245a8)
        3.  [4<sub>4</sub><sub>3</sub> Data Streaming Techniques](#org984b56d)
    5.  [Homework 3](#org5ff9a7f)
    6.  [Midterm](#org82d3985)
5.  [Module 5](#org982862b)
    1.  [Section 5<sub>1</sub>](#org1a039c8)
    2.  [Section 5<sub>2</sub>](#org45ce885)
    3.  [Section 5<sub>3</sub>](#org7b59b15)
    4.  [Homework 4](#orgc547af8)
    5.  [End of Course Eval](#orgb0f40be)



<a id="orge634e36"></a>

# Module 1


<a id="org7bc53a1"></a>

## Overview

-   Categorize the cloud services
-   Purpose on how the cloud is used today


<a id="orgcb16d24"></a>

## Section 1<sub>1</sub>


<a id="org04fec6c"></a>

### Notes:

-   1.1.1 Intro
    -   &#x2026;how its used today
    -   development of I/O systems
    -   history of the infrastructure
    -   using computers we don't own through infrastructure.
-   1.1.2 Utility
    -   utility infrastructure model, contrast to trad&#x2026; trad requires forecast of use and growth.
    -   old way, over buy in anticipation of growth, leaves gaps in utilization / demand
    -   demand is not linear, goes up and down&#x2026; leave surpluses, expensive surpluses, also create deficits
    -   cloud computing is designed from scratch to scale up and down accourding to infrastructure demand
-   1.1.3 From Mainframes to IoT
    -   Mainframes + Terminals &#x2026;
    -   PC's , 1980's, users have their own systems&#x2026;
    -   Networked PCs, centralized storage system, adding security..
    -   1990s-2000s web revolution, web applications, google, facebook, web servers /services
    -   Scalar expansion of web, becoming very complicated,
    -   Internet of Things, giving internet to every device, all over the world, wireless sensors, embedded devices
-   1.1.4 Datacenters and Supercomputers
    -   Datacenters
        -   Explosion of web size == need large facilities for networked computers / servers
        -   very 'fixed' to locations, can't easily relocated datacenters
        -   &#x2026; Mega Datacenters, lot's of HVAC, physical accomodation for power / heat /emissions etc.
        -   need lots of $$, power (1.5% of all USA electricity in 2007), land, skills, etc.
        -   really onlcy practical for a few very, very large companies&#x2026;
    -   Supercomputers
        -   collective computing, exceeding that of other built systems
        -   high processing capability
        -   high data handling cap
        -   unique ability to solve certain computational challenges
        -   require complex scheduling systems
        -   requires advanced / complex networking / fibre / etc
        -   fastes is anhe-2 (china), very elegant MareNostrom (Spain)
    -   1.1.5 CyberInfrastructure
        -   High performance computing
            -   when you have application that exceed the capabilities of desktops
            -   includes: supercomputers, cluster computers, distributed comp, grid comp, exotic hardware (FPGA, etc)
            -   Grid Computing:
                -   HPC built as geogrphicall distributed system from collection of comp, net, storage all via h/s network
            -   Cyberinfrastructure
                -   kewords: DISCOVERY, COLLABORATION
                -   comprised of instruments, sensors, HPC systems, data storage systems, visualization facilities, all networked via h/s
                -   Layers: 0=base, 1=middleware(net, OS), 2=services, 3=applications&#x2026; CyberInfrastructure lives in the middle 2
        -   CLOUD COMPUTER != CYBERINFRASTRUCTURE, but is "part of" cyberinfrastructure,


<a id="org6a96d8b"></a>

### DONE Watch lectures


<a id="org5242877"></a>

### DONE Quiz 1.1 (100pts)


<a id="org3e18ff1"></a>

## Section 1<sub>2</sub>


<a id="orgbf0c811"></a>

### Notes:

-   1.2.1 Benefits of Cloud Computing
    -   Outsource Datacenter
        -   economies of scale
        -   now afford special skills
        -   dev can concentrate on core comp's
        -   shorter lead times
        -   lower capital expenditures
        -   compute power becomes utility commodity like electricity / gas
    -   Benefits cont.
        -   Reduced capital and operating costs
            -   can start small and grow, pay-as-you-go / pay-as-you-grow
        -   Simplified app deployment and management
            -   common programming model across mobile, browser client, server, cloud
            -   access to strong ecosystem of resources
            -   integration with existing IT
            -   vendors handle new tech & integration
    -   Considerations as a Cloud Engineer:
        -   Your instances WILL DIE
        -   You will share resources
        -   the archictecture WILL CHANGE
        -   you will never see the lights
    -   DO NOT TRUST THE CLOUD
        -   you must assume that any failure that can happen in the cloud will happen
-   1.2.2 Common Cloud Vendors
    -   Amazon Web Services AWS (since 2006)
        -   Provide:
            -   different types of services
            -   migration tools
            -   analytics
            -   mobile services
        -   Services
            -   mobile services
            -   machine learning
            -   networking
            -   security
            -   hosting
        -   Scope
            -   covers 190 countries across world
            -   globally located data centers
            -   high reliability, scalable, low-cost infrastructure, high adoption rate
        -   History
            -   2003 B. Black / C. Pinkman paper, aws infrastructure
            -   2004 simple queue service launched
            -   2007 over 180000 dev's using platform
            -   2010 all of amazon.com moved to aws
            -   2011 some major outages suffered, EBS problems
            -   2012 first 'Re-Invent' Conference
            -   2020 commitment to 100% renewable energy
    -   Goolge Cloud
        -   Provides
            -   Compute
            -   Storage
            -   Big Data
            -   Machine Learning
        -   Comparison
            -   slower to roll out services but more mature when rolled out
            -   not as many total services as AWS
        -   History
            -   2008 google app engine announced
            -   2010 google cloud storage launched
            -   2012 google compute engine launched
    -   Microsoft Azure
        -   Provides
            -   Platform as a service
            -   Infrastrucutre as a service
            -   Datacenter Infrastructure
        -   Comparison
            -   not as many services but very very mature and stable
        -   History
            -   2008 annouced windows azure platform
            -   2010 azure commercially available
            -   2014 outage affecting major websited including MSN.com
-   1.2.3 What if Cloud Dies (i.e. vendor pulls the plug)
    -   Consider retaining as much in-house capacity as you need to stay alive, disaster plan
    -   maintain accessibility outstide of cloude / networking infrastructure / bandwidth capacity / etc.
    -   Ultra-Sensitive Data
        -   data you can't trust ANYWHERE else
        -   can't use external cloud but maybe internal cloud&#x2026;
        -   flag your data, go ahead and host low security on cloud, but know what is high and what is low security
    -   Legal aspects
        -   Law requires certain data be handled certain ways
        -   location based: can data be hosted in a different countries datacenter? JURISDICTIONS
        -   content based: health data, financial data, educational data, PII data, etc
        -   Don't rely on LAW to be STATE OF THE ART, LAW is REACTIVE and slow, not PROACTIVE.  THINK AHEAD OF THE LAW.
    -   Cloud availability issues
        -   what assurance that your provider will have enough resources?
        -   how bad of damage if you can't scale up quickly when you needed to (burst situations)?
        -   what remedies if their services fail and cause you damage? (damages covered in SLA, service level agreement)
        -   Amazon approach&#x2026; SPOT MARKET vs GENERAL MARKET, different pricing based on level of assurances


<a id="orgab7388c"></a>

### DONE Watch Lectures


<a id="org5ebcd59"></a>

## Section 1<sub>3</sub>


<a id="orgc72e248"></a>

### Notes:

-   1.3.1 What is the Cloud (3 part definition)
    -   Cloud Characteristics
        -   Common characteristics
            -   massive scale, homgenentiy, virtualization, low cost sftwar, resilient computing
            -   geographic distr, service orientation, advanced security..
        -   Essential characteristics
            -   On demand self services
            -   broad network access
            -   rapid elasticity
            -   resource pooling
            -   measured service
        -   NIST Cloud Computing Model, see slide
            -   Models vary by how much you manage vs how much vendor manages
    -   Service Models
        -   On-prem (private) / You manage all..
        -   IaaS / you manage apps - dbases
        -   PaaS / you manage apps
        -   SaaS / everything managed by vendor (tenant cloud, edge impulse, etc)
    -   Deployment Models
        -   Public
        -   Private
        -   Community
        -   Hybrid
-   1.3.2 Deployment Models
    -   Public
        -   Used by many other entities other than your company
        -   hosted off prem
    -   Private
        -   used only by you
        -   hosted on prem
        -   full control
        -   can have at same time as a public, not mutually exclusive.
    -   Hybird
        -   Some combination of Public / Private, sharing some data, some functions, some storage
    -   4 Deployment models
        -   Enterprize -> Cloud
        -   Private Cloud within Enterprise, resources accessed via INTRANET / LOCAL net
        -   Community Cloud, INTRANET and INTERNET (VPN), linking clouds together securely
        -   Hybrid Cloud, mixing public and private enterprise, intranet and internet, , more complicated.
            -   orchestration systems like Kubernets allows to deploy across hybrid, mixed, setups
    -   Rationale
        -   Private Cloud
            -   data security
            -   avoid vendor lock-in
            -   SLA performance, reliability
            -   cost savings.  sometimes it's cheaper to roll your own, especially if data secrecy is an issue
        -   Enterprise level considerations when going cloud..
            -   CPU/HR , GB/day, ongoing costs
            -   hidden costs, mangement, training, onboarding, etc.
            -   different cloud models required for different applications
    -   Deployment Summary
        -   Clouds (how it's structured / built )
            -   Private
            -   Public
            -   Hybrid
        -   Services (what it does)
            -   IaaS
            -   PaaS
            -   SaaS
        -   Users (how they interact with it)
            -   Dashboards
            -   Browsers
            -   IoT Devices
    -   SaaS Maturity Model
        -   L1: Ad-Hoc / Custom / Single instance per customer "single tenant"
        -   L2: Configurable per customer
        -   L3: Configurable and multi-tenant
        -   L4: Scalable, Configurable, multi-tenant // load balancer between tenant and infrastructure
    -   SaaS Defined
        -   model of software deployment where application is hosted as a service provided to customers across the internet
        -   alleviates burden of software maint / support BUT users relinquish control over version and customization
-   1.3.3 Virtualization & Virtual Machines
    -   Virtualization
        -   you can't physically touch the cloud machines, hardware can and will frequently change
        -   to avoid dependency on specific hardware, write programs for virtual machines from the start
            -   level 5  Cloud Applications
            -   level 4  Cloud Services
            -   level 3  Operating System
            -   level 2  Virtual Machine Manager
            -   level 1  Hardware / Physical
-   1.3.4 Opportunities and Challenge
    -   Benefits
        -   Use high-scale / low-cost providers
        -   anytime/place access via web
        -   rapid scalability up or down and load balancing
        -   no on prem IT staff to hire
    -   Risks
        -   Performance, reliablity, SLA structure
        -   control of data, service parameters
        -   application features / customization
        -   interaction between cloud providers
        -   non standar API - mix of SOAP and REST
        -   privacy, security, trust..
        -   some think the return to supercomputer is opposite of what pc's gave us, freedom from mainframe
        -   high integration means high dependency
        -   monopolies
-   1.3.5 Advantages (Detailed)
    -   Lower computer costs
        -   less power, less compute required
        -   since apps run on cloud, less local storage req'd
        -   PC itself can be less expensive, thin client
        -   PC needs fewer peripherals, cd's, dvd's, etc.
    -   Improved Performance
        -   fewer large programs running on PC, fewer resources consumed, pc is "faster" or at least less occupied
        -   fewer memory processes, services running, thing boot up faster and run more smoothly
    -   Reduced Software Costs
        -   fewer expensive software purchases per device
        -   usually have access to suite of tools would otherwise need to purchase separately (g-suite, o365, etc)
    -   Instant Software Updates
        -   No longer responsible for patching yourself
        -   updates scheduled automatically
        -   when access via web client, always getting the latest version
    -   Improved document format compatibility
        -   everything using standardized extensions, file formats, etc (.docx, .pdf, .csv, etc)
        -   if everyone sharing doc's through same cloud, should never be a format or versioning conflict.
    -   Unlimited Storage Capacity
        -   Cloud computing == virtually unlimited storage
        -   PC 1TB is tiny compared to cloud storage
    -   Increased Data Reliability
        -   If one node goes down, data is still safe
        -   Cloud acts like a data safe, archive
    -   Universal Document Access
        -   no problem with cloud because not taking documents with you
        -   docs live and remain in cloud, you access and edit them as you need through a portal
        -   docs are instantly available regardless of where you are.
    -   Latest Version Available
        -   No complicated migrations / upgrades / conversions
        -   Cloud always has latest version of docs and apps both
    -   Easier Group Collaboration (remember SharePoint :(  )
        -   Sharing docs easily and reliably == more collaboration
        -   can allow many users access to few docs with out fear of issues
        -   multiple users can collaborate on multiple projects all at same time
    -   Device Independent
        -   agnostic, no pref Mac, Win, Linx, etc
        -   hardware agnostic, no pref pc, thin client, desktop, etc
-   1.3.6 Disadvantages (Detailed)
    -   Always on Internet Connection
        -   cloud compute impossible w/o reliable connection
        -   internet used both for applications and documents.  I.E. MS-Word and Documents / Excel and Spreadsheets / etc.
        -   dead internet == no work being produced
    -   Poor performance if low-speed connections
    -   Features might be limited
        -   fewer options with cloud Word vs Office Word, etc
    -   Can be slow
        -   constantly handling files, back and forth between client and server, etc
    -   Stored data may not be secure
    -   Stored data can be lost
        -   need some kind of phys backup
    -   HPC Systems
        -   not clear you can run heavy software from cloud
        -   Scheduling resources
    -   General Concers
        -   Each cloud vendor using different protocols / different API's
        -   i.e. amazon created it's on DB system (not SQL)


<a id="org532203f"></a>

### DONE Watch Lectures


<a id="org2c3897e"></a>

### DONE Quiz 1.3 (100pts)


<a id="org6a4efdd"></a>

## Section 1<sub>4</sub>


<a id="org35af49e"></a>

### Notes:

-   1.4.1
    -   IaaS: OpenStack
        -   Open source cloud computing platform
        -   Infrastructure as a service solution
        -   Many independent services
    -   Quick Facts:
        -   joint project by rackspace and NASA
        -   launched in 2010, now community of 15,000 people in 136 countries
        -   OpenStack 1 million+ lines of code in Python
    -   Community Support
        -   over 200 companies helping
    -   High level architecture
        -   [Overview](https://access.redhat.com/webassets/avalon/d/Red_Hat_OpenStack_Platform-11-Architecture_Guide-en-US/images/fce6394275bd3444892c5d3a91ccf17c/RHEL_OSP_arch_347192_1015_JCS_01_Interface-Overview.png)
            -   Dashboard is launch point, provides UI to:
                -   network, storage, compute, identity, image, object storage.
-   1.4.2
    -   OpenStack Services
        -   <span class="underline">Compute: NOVA</span>
            -   on demand networked virtual machines
            -   KVM & Xen available choices for hypervisors or linux container like Docker
        -   <span class="underline">Network: NEUTRON</span>
            -   allowing users to create their own networks and then attach interfaces to them
            -   highly configurable
            -   legacy networksing: nova-network
                -   simplicity
                -   lack functionality like VPN, load balancing, firewall. (EDIT, it now has these abilities)
        -   <span class="underline">Block Storage: CINDER</span>
            -   provides persistent block level storage devices for openstack instances
            -   manages the creation attaching and detaching of the block devices to servers
        -   <span class="underline">Objecst Storage: SWIFT</span>
            -   accepts files to upload, modifications to metadata, mods to container creation
            -   swift architectre is very distributed, no single point of failure, scales horizontally
        -   <span class="underline">Identity: Keystone</span> (difficult to configure, easy to lock yourself out)
            -   provides single point of integration for OpenStack polic, catalog, token, and uthentication.  like group policy object
            -   supports multiple forms of authenticaiotn including standard usernameand password credentials, token-based systems and AWS-style.
            -   User.Tenant.Role.
        -   <span class="underline">Image Storage: GLANCE</span>
            -   provides discovery, registration, and delivery services for disk image servers
            -   can also be used to store and catalog unlimited number of backups
        -   <span class="underline">Dashboard: HORIZON</span>
            -   Bringing together all of the above for user access UI
            -   provides administrators graphical interface for access, provisioning, automation.
        -   <span class="underline">Compared to AWS</span>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Service</th>
<th scope="col" class="org-left">OpenStack</th>
<th scope="col" class="org-left">AWS</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">compute</td>
<td class="org-left">Nova</td>
<td class="org-left">EC2</td>
</tr>


<tr>
<td class="org-left">Network</td>
<td class="org-left">Neutron</td>
<td class="org-left">VPC</td>
</tr>


<tr>
<td class="org-left">Blk Strge</td>
<td class="org-left">Cinder</td>
<td class="org-left">EBS</td>
</tr>


<tr>
<td class="org-left">Obj Strge</td>
<td class="org-left">Swift</td>
<td class="org-left">S3</td>
</tr>


<tr>
<td class="org-left">Img Mgmt</td>
<td class="org-left">Glance</td>
<td class="org-left">AMI</td>
</tr>


<tr>
<td class="org-left">Dashboard</td>
<td class="org-left">Horizon</td>
<td class="org-left">Console</td>
</tr>


<tr>
<td class="org-left">Identity</td>
<td class="org-left">Keyston</td>
<td class="org-left">IAM</td>
</tr>
</tbody>
</table>


<a id="orgc8b61d9"></a>

### DONE Watch Lectures


<a id="org9608a7d"></a>

### DONE Homework 1: IaaS Infrastructure (140pts) <code>[8/8]</code>

-   [X] Keystone <code>[4/4]</code>
    -   [X] Generate Token
    -   [X] Generate demo and admin users
    -   [X] Retrieve User list
    -   [X] Retrieve role list
-   [X] Glance <code>[2/2]</code>
    -   [X] import cirros OS image
    -   [X] retrieve image list
-   [X] Nova <code>[3/3]</code>
    -   [X] retrieve VM list
    -   [X] create VM
    -   [X] login to VM
-   [X] Neutron <code>[1/1]</code>
    -   [X] create a network
-   [X] Horizon <code>[2/2]</code>
    -   [X] login with proper account
    -   [X] retrieve service info
-   [X] Cinder <code>[2/2]</code>
    -   [X] create a volume
    -   [X] retrieve volume list
-   [X] Swift <code>[2/2]</code>
    -   [X] create a container
    -   [X] upload and download files
-   [X] Extra Points <code>[4/4]</code>
    -   [X] create a VM with public network connected
    -   [X] import and create a vm with ubuntu image inside openstack
    -   [X] attach volume to VM
    -   [X] install one extra service (Ceilometer, Heat, etc)


<a id="orga7e61cd"></a>

# Module 2


<a id="orgf3e91da"></a>

## Overview


<a id="org9578e47"></a>

## Section 2<sub>1</sub>


<a id="org7e569dc"></a>

### DONE 2<sub>1</sub><sub>1</sub> AWS Intro

-   AWS Biz:
    subsidiary of amazon, pay as you go, cloud on demand, launched in 2002
-   server farms throughout the world
-   @2020, 212 services
-   2017, dominant 34% of cloud
-   Collection of remote compute services&#x2026;
-   Compute:
    -   Elastic Compute EC2
    -   Elastic MapReduce (EMR), hadoop on EC2
-   Storage
    -   Simple Storage Service (S3) - storage
    -   Glaciaer = low cost long term storage (high redundancy, low access time)
    -   Elastic Block Storage (EBS) - persistent block storage
-   Database
    -   DynamoDB = NoSQL backed by SSD
    -   ElasticCache = in-memory cache based Memcached
    -   Relational databse services (RDS) = MySQL, Postgres, Aurora w/ MySQL
-   Platform Model:
    -   | Deployment & Admin |
    -   | App Services
    -   | Compute | Storage | Database |
    -   | Networking |
    -   | AWS Global Infrastructure |


<a id="org0c618bb"></a>

### DONE 2<sub>1</sub><sub>2</sub> AWS Infrastructure

-   World wide, divided into regions, i.e. Europe, SA, US, etc
-   Availability 'Zones'
-   Region = geographic area.  Regions have multiple 'locations', 11 regions.
-   Each region has 2 availability zones, distinct data centers
-   Each EC2 region isolated from each other
-   failover and fault tolerance built into the cloud already, all we have to do is build our applications.
-   Edge Locations
    -   52 edge locations
    -   Edge locations are CDN edge poitns
        -   more edge locations than regions
    -   Used to cache data physically close to the user
-   Global infrastructure
    -


<a id="org3978818"></a>

### DONE 2<sub>1</sub><sub>3</sub> AWS Networking

-   Domain Name System, port 53, HA & Scalable DNS
-   'Router 53' is the name of the AWS service
-   VLAN: AWS Direct connect uses vlan. 802.1q
    -   dedicated connection, multiple vitural nic
-   client can use same conenctio for private and public management traffice
-   AWS Direct Connect:  High Throughput dedicated, 10gb/s,
-   VPC Virtual Private Cloud: provisionally logically isolated section of aws cloud wehre you can launch aws resources in a virtual network that you define.
-   i.e. create a public store front, publice facing subnet for webservers


<a id="org9ccbe37"></a>

### DONE 2<sub>1</sub><sub>4</sub> AWS EC2 & EBS

-   EC2 Elastic Compute (re: Nova)
    -   reconfigurable capacity
    -   provision virtual instances (os's)
    -   marketplace for pre-configured instances
    -   uses Xen virtualization (Xen = hypervizor)
    -   Elastic load balancing done automatically
        -   scaling based on demand
        -   min and max instance thresholds
        -   triggers for scaling in and scaling out
        -   uses metrics collected by aws `cloudwatch`
        -   free
-   EBS Elastic Block Storage (re: Cinder)
    -   Data.  Datastores, content networks, databases, all the assests your web apps need to either store or present over the web.
    -   Mount specific BLOCK devices (i.e. sda1, sdh, sdb, etc) logical drives.
    -   BLOCKS available (like vmware datastores) to multip vm's from variety of use scenarios.
    -   can be up to 1TB ea
    -   EBS built on replicated storage so if one phys device goes down, can failover to another.
    -   EC2 handles INSTANCES / EBS handles STORAGE


<a id="org2606bc5"></a>

### DONE 2<sub>1</sub><sub>5</sub> Google Cloud

-   GCP Google Cloud Platform
-   infrastrucutre services; Google Search, Gmail, YouTube all sparked the GCP growth
-   IaaS, PaaS, and serverless computing environments
-   1st, need datacenters.  Distributed world wide.  Low latency
-   600 services
-   divided by types; Ingest, Storage, Process / Analyze, Explore & Viz
-   Market share, GCP growing but still a fraction of AWS


<a id="orgb15a681"></a>

### DONE 2<sub>1</sub><sub>6</sub> MS Azure

-   MS AZURE, (formerly WINDOWS AZURE)
-   same IaaS / Paas model
-   somewhat specialized to MS products (office)
-   Big differ between AWS and Azure is 6-8yr head start with AWS
-   Azure has lots of datacenters, some specifically USGOV
-   54 Regions around globe, increasing ea year (54 @ 2018)
-   1 Azure GEOGRAPHY has multiple REGIONS
-   Stack:
    -   App Services
    -   Software Services
    -   Platform Services (SQL | .NET | Live | Share-Point | CRM)
    -   Infrastructure Services
-   Details of AZURE LAYER
    -   specialized OS called Microsoft Azure, runs "fabric layer"
    -   manages compute and storage resource clusters within MS datacenters that it then presents to the application layer running on top of Azure Layer
    -   Described as a "cloud layer" running on top of a number of Windows Server systems (Windows server 2008), optimized for Hyper-V hypervisors.
-   Design of AZURE
    -   Scaling of compute and storage controlled by "fabric" layer
    -   Also provides management (i.e. Keystone & Nova)
-   Benefits of AZURE
    -   easy for windows users / offices
    -   active directory, sharepoint, O365, etc
    -   less overhead for IT staff
-   .. vs GCP
    -   GCP stronger in ML, big data, container support
-   .. vs AWS
    -   AWS hyper generalized, open standards, everything to everyone
-   Overall cloud biz
    -   2018 200 billion, 2022 340 billion, &#x2026;
-   No public data avail on how big AZURE really is
-   Amazon specifies AWS revenue, MS only reports Azure growth rate (2019 62%, 2018 78%) over previous (compound ?)


<a id="org5cc9656"></a>

### DONE Quiz 2<sub>1</sub>


<a id="orge369732"></a>

## Section 2<sub>2</sub>


<a id="orga160bc7"></a>

### DONE 2<sub>2</sub><sub>1</sub> Cloude Edge

-   Clients talk to clouds via web browsers & standards
    -   just the outer 'skin' of it though
    -   much more going on underneath, can host entire businesses end to end
-   Big Picture..
    -   Client req handled by first tier layer, PHP, ASP etc
    -   these are light services, very fast, nimble
    -   first tier caches info (ssl, keys, etc) for use in second tier)
    -   second tier is called 'shards'
-   Many styles of 'cloud' system
    -   at the edge, cloud is taylored for vast # of clients and quick response
    -   further inside, taylored to high volume services that run pipeline of info
    -   deepest inside, world of virtual computer clusters, scheduled with each other, being controlled and scheduled by mapreduce&#x2026;
-   Outer Tiers: replication is KEY
    -   replicate PROCESSING
    -   replciate DATA
    -   replicate CONTROL INFORMATION (keys, ssl, managment info)


<a id="org4b7fa02"></a>

### DONE 2<sub>2</sub><sub>2</sub> Sharding

-   Sharding happens at TIER 2
-   This is where caching first takes place (last search, ssl keys, cookies)
-   Sharding is a method for allocating data items to nodes of a distributed caching or storage system based on the result of a hash function computed on the item identifier. It is ubiquitously used in key-value stores, CDNs and many other applications.
-   Caching in tier 2 is what makes tier 1 work
    -   ..always use cached data when possible
    -   ..replicate data within cache to spread load
    -   ..not everything needs to be fully replicated, so we use 'shards' with just a few replicas
    -   ..uses key value pairing to securely link caches to their users, destinations, services, etc.
-   Sharding is readlly HORIZONTAL scaling.  SPREADING the ability to ACCESS the cloud across mulitple instances.
-   HOW? database table example.  Like breaking down 10,000 row database into smaller tables, with also smaller indecies, and running them in parallel across more instances.  Same singular table data, but all runs and accesses faster while also having some built in fault toleration.  (1 table going down won't take out whole database)
-   Smaller indexes = = faster queries = = faster applications
-   Example Cache services (kw DISTRIBUTED HASH TABLE):
    -   Memcached / Redis
        -   in-memory key-value stored chuncks of arbitrary data
    -   Dynamo
        -   service created by amazon
    -   BigTable
    -   IBM WebSphere eXtreme Scale
-   Necesasry to ALWAYS shard data?
    -   YES.  if almost every external request is going to use it anyway, YES DO SHARD
    -   understands patterns of access to the cloud data /services you manage
-   UPDATING REPLICAS
    -   So yo uhave replicas now, of course you need to sync / update them right
    -   also happens according to 'patterns' of access
    -   some can be singular updated, others must be done across parallel machines running concurently
    -   term sharding is for data, but might talk about 'parallel computation on a shard'
    -


<a id="org5a99d55"></a>

### DONE 2<sub>2</sub><sub>3</sub> Critical Path

-   Critical path.. notion of what is important in a querie / request..
-   what actions contribute to any percievable delay between the user's request and the response to their request.
-   What if a request triggers and update
    -   if updated done asynchronously, user might not notice on their end..
        -   often work this way
        -   avoids waiting for slow services to prcess the updat but may force their tier-one services to 'guess' outcomes
    -   Many cloud systems use these sort of tricks to speed response times
-   Tier 1 PARALLELISM
    -   parallelism speeds up first tier services
    -   asks itself, will it be faster&#x2026;
        -   for x to just compute response
        -   or for x to subdivide work by spreading it out over subservices
    -   `Werner Vogels` (amazon) commented that amazon pages have content from 50 or more parallel sub services that ran, in real time, your request!
    -   networks, data centers, infrastructure can all faile along the way adn create inconsistencies..


<a id="org48b15d1"></a>

### DONE Quiz 2<sub>2</sub>


<a id="org6645ff4"></a>

# Module 3


<a id="org385a62b"></a>

## Overview

-   Concepts:
    -   CAP Theorem
    -   Failure Modes
    -   Stronge and Eventual Consistency
    -   Partitioning Algorithms


<a id="org7e3e99d"></a>

## Section 3<sub>1</sub>


<a id="org5196455"></a>

### DONE 3<sub>1</sub><sub>1</sub> CAP Theorem

-   KW 'Distributed Systems'
-   ref Eric Brewer (keynote ACM PODC 2000)
    -   Pick 2&#x2026;
    -   Consistency, Availability, Partition Tolerance
    -   only possible to get 2/3
        -   Consistency: all nodes see same data at same time
        -   Availability: every req gets a reply
        -   Partition Tolerance: system continuse to operate despite arbitrary message loss / failure of parts / fracture
-   Interactions with Web Services
    -   operations commit or fail in entirety (ATOMIC)
    -   committed transaction are visible to all future trx (CONSISTENT)
    -   un-commited trx isolated from each other (ISOLATED) like git
    -   once commited, trx is permament (DURABLE)
-   Consistency: Atomic Data Object
    -   total order on all operations such that each operation looks as if it were complete at a single instance
    -   equivalent to requiring req's if the distributed memory to act as if they were executing in a single node, responding to operations one at a time.
    -   Atomic read/write shared memory
        -   any read operation that begins after a write operation completes must return THAT value, or the result of a later write operation
-   Consistency: What does it mean?
    -   re CAP Theorem means 2 things;
        1.  That update to same data item are applied in some agreed-upon order
        2.  that onece an update is achnowledged to an external user, it won't be forgotten.
    -   Not all systems need both properties
-   Consistency: Risks (also inconsistencies)
    -   inconsistency causes bugs
        -   client can't trust the servers&#x2026;
    -   Weak or Best Effort consistency&#x2026;
        -   strong security guarantees DEMAND consistency
        -   would user trust medical health data to system with weak consistency?
-   ACID to BASE
    -   ACID
        -   [A]tomic:  all trx succeeds, or roll back pre trx
        -   [C]onsistent: can't leave incompleted
        -   [I]solated: can't interfere / contradict each other
        -   [D]urable: completed trx's persist, even when servers reboot.
    -


<a id="org93ffaae"></a>

### DONE 3<sub>1</sub><sub>2</sub> CAP Theorem Examples

-   Book Store / Shop:
    -   to keep inv accurate, maybe you lock database once trx starts so that only ever the actual inventory is displayed in web..
    -   &#x2026; only works in small scale, consider larger example, like amazon.
    -   if big, maybe you used cached data&#x2026;
    -   if big, maybe consider violating AC[I]D isolation, let transactions contradict each other to an extent&#x2026;
-   Vogels @ Amazon
    -   CTO at amazon
    -   involved in buiding a new shopping cart service
        -   old one used strong consistency for replicated data
        -   new one built over DHT distributed hash table (CHORD), weak consistency, but eventual convergence
        -


<a id="org7cb1888"></a>

### DONE 3<sub>1</sub><sub>3</sub> CAP Theorem Details

-   Consistency: Eventual / Convergence
    -   informal guarantee that if no new updates, eventually all accesses to item with return last updated result
    -   i.e. BASE:
        -   [B]asically
        -   [A]vailable
        -   [S]oft state
        -   [E]ventual consistency
-   Core Problem
    -   when can we sweep consistency under the rug?
        -   if we weaken a safety critical property, bad things can happen&#x2026;
        -   sites like amazon and ebay do OK w/ weak guarantees, model just doesn't demand otherwise&#x2026;
        -   embracing weaker nature, reduces syncronization, better response time
    -   but what if applications in question are high-assurance, must be accurate every transaction??
    -   [A]vailability (C[A]P):
        -   for a distributed system to be condinuously available, every request received by non-failing node must result in a response
        -   any algorithm used by the service MUST eventually TERMINATE
        -   no BOUNDS on how long algorithm may run before TERMINATING, therefore susceptible to UNBOUNDED computations&#x2026;
    -   [P]artition Tolerance (CA[P]):
        -   network allowed to lose messages from one node to another
        -   when partitioned messages between nodes in different partitions are lost
        -   requirements:
            -   atomicity: every response is atomic / even though parts of messages might not be delivered
            -   available: every node receiving a request MUST provide a response / even though parts of messages might not be delivered.
            -   if system behaves AS IF all nodes were AVAILABLE, then it is considered partiion tolerant
    -   Web Services problem:
        -   similarly expected to by HIGHLY AVAILABLE (every req gets a resp)
        -   when services go down, cause real world problems (finance, healthcare, telecomm, etc)
        -   FAULT TOLERANCE:
            -   When some nodes crash or some communication links fail, it is important that the services still performa as expected. One desirable fault tolerance property is the ability to survive a network partitioning into mulitiple components..
            -


<a id="orgeccdfc8"></a>

### DONE 3<sub>1</sub><sub>4</sub> CAP Theorem and the Cloud

-   Is CAP valid in the CLOUD ??
    -   data centers networks don't normally have partition failures&#x2026;
        -   but wide area links do fail&#x2026;
        -   most services design to do updates in single place and mirror read only data to others..
        -   so CAP scenario can't really pop up&#x2026;
    -   Brewer's arguments about not waiting for a slow service to respond make sense
        -   Argues for using any single replica you can find&#x2026;
        -   but does this preclude that replica being CONSISTENT??
-   Properties you might want in the CLOUD
    -   CONSISTENCY: updates in specified order
    -   DURABILITY: once accepted, not forgotten
    -   real-time RESPONSIVENESS: replies within BOUNDED delay
    -   SECURITY: only permits AUTHORIZED actions by AUTHORIZED parties
    -   PRIVACY: won't discloser personal data
    -   FAULT-tolerance: failures can't prevent system from providing desired results
    -   COORDINATION: actions won't interfere or contradict each other
-   Cloud services and their properties

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Service</th>
<th scope="col" class="org-left">Properties it guarantees</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">Memcached</td>
<td class="org-left">No special guarantees</td>
</tr>


<tr>
<td class="org-left">Google GFS</td>
<td class="org-left">File is current if locked</td>
</tr>


<tr>
<td class="org-left">BigTable</td>
<td class="org-left">Shared key-value pair with consistent properties</td>
</tr>


<tr>
<td class="org-left">Dynamo</td>
<td class="org-left">Amazon shopping cart eventual convergence</td>
</tr>


<tr>
<td class="org-left">Databases</td>
<td class="org-left">Snapshot isolation</td>
</tr>


<tr>
<td class="org-left">MapReduce</td>
<td class="org-left">functional compute model w/ strong guarantee</td>
</tr>


<tr>
<td class="org-left">Zookeeper</td>
<td class="org-left">Yahoo! file system, sophisticated properties</td>
</tr>


<tr>
<td class="org-left">PNUTS</td>
<td class="org-left">Yahoo! database, shared data, consistency options</td>
</tr>


<tr>
<td class="org-left">Chubby</td>
<td class="org-left">locking services, strong guarantees</td>
</tr>
</tbody>
</table>

-   Conclusions:
    -   Notice that services&#x2026;
        -   most of them cost 10's or 100's of MILLIONS to create..
        -   huge investment upfront
        -   i.e. Oracle has billions invested..
    -   CAP isn't about telling ORACLE how to build a database product&#x2026;
        -   CAP is a warning to YOU that strong properties CAN easily lead to SLOW services
        -   but thinking in terms of WEAK properties is often SUCCESSFUL strategy that yields good solutions requiring less effort


<a id="org48851b0"></a>

### DONE Assignment: CAP Theroem Reading Notes

1.  [X] Spanner, TrueTime & CAP &#x2026;
    1.  Read & Review
2.  [X] CAP 12 years later&#x2026;
    1.  Read & Review
3.  [X] Submit summary


<a id="orgb55ab2d"></a>

## Section 3<sub>2</sub>


<a id="org32e848a"></a>

### DONE 3<sub>2</sub><sub>1</sub> [C]onsistency

-   Tiers:
    clouds have tiers, levels.
    -   tier 1: lightweight, responsive, web based, also route or handle some services
    -   tier 2: key value pair. stores / caches credentials and authorizations.
    -   tier (inner): online services that handle requests not handled in the first tier.  persistent files, transactional services, shielded from load though.
    -   tier (backend): running offline services, indexing web overnight, updates, scheduled loads,
-   Replication:
    -   core feature of cloud
    -   to handle more work, make more copies
    -   if load increases, make more copies&#x2026;
    -   if load decreases, kill redundant duplicates&#x2026;
    -   load balancing: spread requests over the duplicated nodes
-   Things we can replicate in the cloud:
    -   Files / Storage
        -   compare "write once" data (images, photos) to evolving data (spreadsheets, inventory, logs, etc)
    -   Computation
        -   replicate a single request and distribute it across the duplicated nodes to share comp load
    -   not just FASTER, also more FAULT TOLERANT
-   Things to "MAP" in REPLICATION
    -   data
    -   fault tolerant req processing
    -   coordination and syncronization
    -   parameters & configuration data
    -   security keys and credentials
    -   user / group / membership information (like AD, GPO)
-   ..back to CONSISTENCY
    -   want REPLICATED data to behave in CONSISTENT manner
    -   an INCONSISTENT service appears as BROKEN
    -   DIFFICULT CHALLENGE, how to get many copies to act like just one??
-   IMPLEMENTATION
    -   need a 'reference' system, some kind of MASTER copy
-   DANGERS of INCONSISTENCY
    -   lack of TRUST
    -   when to trust "weak" or "best effort" consistency?
    -


<a id="org2c19e5d"></a>

### DONE 3<sub>2</sub><sub>2</sub> Distributed Systems

-   Definition:
    A collection of automata whose distribution is transparent to the user so that the system appears as one local machine.  This is in contrast to a network, where the user is AWARE that there are several machines, and their location, storage, replication, load balancing, and functionality is not transparent.  DISTRIBUTED systems usually use some kind of client-server organization.
-   Definition cont:
    [Andrew Tanenbaum] a distributed system is a collection of independent computers that appear to the suers of the system as a single computers
-   Definition cont:
    [Michael Schroder] a distributed system is several computers doing something together.  Thus, a distributed system has three primary characteristics: multiple computers, interconnections, and shared state.
-   Basic building blocks:
    -   RPC, remote procedure calls
    -   DO, distributed objects
-   Distributed Services
    -   2PC/3PC and Paxos
    -   REPLICATION control
-   Cloud Computing
    -   Gossiping
    -   key-value pair / nosql stores / caches / credentials
    -   stream processing (DATA in TRANSIT)
-   Legacy Layers (old but still important)
    -   Distributed File Systems
    -   Distributed Shared Inventory
    -   Self Stabilization
-   Very IMPORTANT..
    -   Security and BYZANTINE FAULT-TOLERANCE
-   High level GOALS of DISTRIBUTED systems:
    -   Heterogeneity: varried services, but with same guarantees
    -   Robustness: fault-tolerant
    -   Availability: of data & operations despite failures / network partitions
    -   Transparency:
    -   Concurrency: support many clients
    -   Efficiency: fast ops, reads, & writes
    -   Scalability: many ops per second despite thousand of services / millions of users
    -   Security: system should be protected from attackers and bugs
    -   Openness: each system built on top of other services/potocols, layered stack architecture
-   Some intricacies of DISTRIBUTED systems
    -   Syncronization: multiple clocks, difficult to agree on exact time
    -   Concurrency: multiple SIMULTANEOUS accesses potential to CONFLICT
    -   Failures: High probability (guarantee?) of failures, many moving parts.
    -   Consensus: difficult to reach consensus, lack of synchronization, who has best latest copy  of data?
-   different DISTRIBUTED system MODELS, CURRENT
    -   Client/Server
    -   Multi-tier
    -   Peer-to-Peer
    -   Agent based system
    -   Mobile CODE
    -   Service-orientec computing
    -   Cloud Computing
-   EMERGING DISTRIBUTED system MODELS
    -   Cloud, Edge, Beneath the Cloud
    -


<a id="org9188fab"></a>

### DONE 3<sub>2</sub><sub>3</sub> Two Phase Commit

-   addressing the [C]onsistency issue:
    -   [Leslie Lamport] DON'T USE CLOCKS, clocks contradict each other, who wins?
    -   use LOGICAL CLOCKS. i.e. if [B] happens after [A], response to [B] must be at least as current as response to [A]
    -   also researched&#x2026; VECTOR CLOCKS (but not in this material)
-   hence 2 PHASE COMMIT
    -   a kind of building block for a LOGICAL CLOCK, tied to 'consensus' or 'agreement'
    -   TRANSACTION:
        1.  assign transaction and ID
        2.  GET pending state
            1.  updated done at various places visited..
            2.  read and update or write lock&#x2026;
        3.  if WRONG, ABORT.
        4.  OTHERWISE, request a COMMIT (commit can fail though)
-   

-   


<a id="orgbb24d43"></a>

### DONE QUIZ 3.2


<a id="org0a666df"></a>

## Section 3<sub>3</sub>


<a id="org6429041"></a>

### DONE 3<sub>3</sub><sub>1</sub> Byzantine Failures

-   Failure Detection in a newtwork
    -   Many think of SKEEN's 3PC as a practical protocol..
    -   but to use it one needs perfect failure detection that never makes mistakes
    -   is it even possible to build such a failure detection
-   Notions of FAILURE
    -   types of failure models?
    -   lots of things can go wrong:
        -   networks drop packets
        -   links break
        -   processes fail / hang
        -   clock malfunction, go out of sync
        -   a machine could freeze up then resume
        -   processes can corrupt memory yet not quite crash
        -   processes can be hijacked by viruses / malware..
    -   EXAMPLE: Byzantine Failure @ Amazon
        -   2008: AWS S3 brought down for several hours.  Single bit hardware error propogated throughout system..
        -   <http://status.aws.amazon.com/s3-20080720.html>
    -   REAL systems
        -   LINUX and WINDOWS use timers for FAILURE detection
            -   can fire even if remote side is healthy
            -   possible to get innacurate failure detection, false pos failure
            -   using time, many types of failure can be detected
        -   Some APP depend on TCP, but TCP also uses timers at it's core and has same problem
    -   BYZANTINE failure model
        -   much debated..
        -   since programs are buggy, always apealing to use such a model.  A bug gives a random corrupt behavior, like a mild attack
        -   but BYZANTINE model is hard work with and can be costly (must 'outvote' the bad process)


<a id="orgdc467e3"></a>

### DONE 3<sub>3</sub><sub>2</sub> Examples of Failure Modes

-   FAILURE MODES (cont)
-   Recall, 2PC and 3PC normally used, std in linux & windows, rely on timers to detect failures
    -   prone to mistakes, i.e. P thinks L is faulty but L is really fine.
-   VOGELS: World wide failure sensing technique
    -   VOGELS wrote a paper, argued we could do much better than BYZANTINE
        -   cloud managment layer, forces slow nodes to crash and restart&#x2026;
        -   so management layer already a trusted partner more robust than most nodes&#x2026;
    -   'POSTMAN ALWAYS RINGS TWICE'
        -   suppose mailman wants signature, rings bell, waits, no answer, does he assume you DIED?
        -   hopefully not&#x2026;
        -   VOGELS suggest multiple reasons machines timeout but are not faulty
-   Causes of delay in CLOUD..
    -   Scheduling can be sluggish,
    -   node might get BURST of messages, temp overflow sockets, triggers message loss,
    -   machine might become overloaded, too many vm's,
    -   application might run wide, page heavily,
-   VOGELS suggestions..
    -   ADD some kind of failure monitoring SERVICE as a STANDARD network component,
    -   instead of relying on TIMEOUT, even protocols like RPC and TCP would ASK the SERVICE and it would tell them,
    -   set it up to do some inquiry, sleuthing first.  ask the OS for info on that machine, check network, etc.,
-   Why clouds DON'T do this&#x2026;
    -   in clouds, focus is on keep MAJORITY of system running,
    -   not concerned with the WHY or EXCUSE for a failing node, just move on,
    -   keeping cloud up as a WHOLE is more valuable than waiting for slow node to catch up,
    -   END USER EXPERIENCE IS WHAT MATTERS MOST
    -   So, cloud is casual about killing things
    -   avoids failure monitoring SERVICES because could become bottlenecks.
-   More reasons&#x2026;
    -   most sofware is buggy
        -   BOHRBUGS and HEISENBUGS
            -   BOHRBUGS: boring and easy to fix
            -   HEISENBUGS: seem to hide when troubleshooting, caused by concurrency problems, hard to fix, crashes can seem unrelated to the bug
    -   Studies show that BUGS persist throughout LIFETIME of software no matter how mature
    -   if something acting strange, maybe it's failing,
-   More reasons &#x2026;
    -   TIMING is flakey
        -   at cloud scale, w/ millions of nodes, CANNOT trust TIMING,
        -   too many things can cause problems, show up as timing faults or time out incorrectly


<a id="org0487041"></a>

### DONE 3<sub>3</sub><sub>3</sub> Synchronous and Asynchronous Execution

-   SYNCHRONOUS
    -   messages ARRIVE on time,
    -   &#x2026; PROCESSES share synch clock
    -   &#x2026; failured detected easily
-   ASYNCRHONOUS
    -   NONE OF THE ABOVE
-   Clouds are NEITHER
    -   Designed around ASYNCHRONOUS, but clocks do work most of the time,
    -   the systems all have clocks, the SOFTWARE TREATS the system as ASYNCHRONOUS, but in practice we do have access to time.
    -   BEGIN as ASYNCHRONOUS, as resources allow, can ENRICH system with some SYNCHRONOUS tools,
-   SUMMARY,
    -   3PC in theory is better than 2PC, but world doesn't work perfectly enough for 3PC
    -   3PC more costly, extra communication round, but still blocks / fails
    -   failure detection tools could help, but cloud is not a good fit for failure detection services,
    -   cloud transactions REQUIRE active, health loggin service.  If it goes down, could transaction subsystem hangs till restart.
    -


<a id="org5cae47f"></a>

### DONE 3<sub>3</sub><sub>4</sub> Data Partioning

-   Definition:
    a technique to break up big database (DB) into many smaller parts
    -   process of splitting DB tables across multiple machines,
    -   improves performance, reliability, availability
    -   justified because it is cheaper and more feasible to scale horizontally by adding more machines than to grow vertically by building bigger individual servers
-   Many different schema / approaches
    -   horizontal partioning
    -   vertical partioning
    -   directory based partioning
-   HORIZONTAL partitioning
    -   push different rows to different tables, aka range based partioning (all columns, split up rows)
    -   PROBLEM: have to very carefully divide up or partion will be unbalanced
        -   zip code distribution example
-   VERTICAL partitioning
    -   divides the data by features, making servers specialized to what groups of database features they are managing
    -   straightforward to implement, low impact on application
    -   PROBLEM: if project grows significantly, may need to further partition a feature specific DB across various servers (not possible for single server handle it all)
-   DIRECTORY BASED partioning
    -   Loosely built around the issues mentioned above.  idea is to creat a lookup service which knows your current paritioning schema and abstracts it wasy from the DB access code.  Query the directory service, it holds the map, it will return a path to get what info you want.  "loosely coupled" so that means we can perform tasks like adding servers to teh DB pool, change partition scheme, all without having impact on the application.
-   PARTIONING CRITERIAS
    -   Apply hash function to some key attribute of entitiy being stored, that yields partition number..
    -   i.e., if have 100 DB servers, & ID is numberic, incremented 1 each time&#x2026;
    -   hash function could be 'ID%100' which will give server number where we can store/read that record.  should ensure a uniform allocation of data among server
    -   PROBLEM: effectivly creates a fixed number of DB servers, adding servers would mean changing the hash function, which would require redistribution of data, downtime
    -   WORKAROUND: use CONSISTENT hashing
    -   another option LIST PARTITIONING
        -   each partition assigned a list of values, so whenver we want to insert a new record, we will see which partition contains our key and then store it there.  for example, we can decide all users living in Iceland, Norway, Sweden, Finland, or Denmark will be stored in a partition for 'NORDIC' countries.
    -   another option: ROUND ROBIN
        -   very simple.  with 'n' partitions, the 'i' tuple is assign to partition (i mod n),
    -   another option: COMPOSITE PARTITIONING
        -   combine any of the above partition schema to devise new scheme. i.e. first applying list partitioning schem and THEN a HASH based PARTITIONING.


<a id="orgbdf69d9"></a>

### DONE QUIZ 3.3


<a id="orgdfb83bb"></a>

## Section 3<sub>4</sub>


<a id="orgb8e55ec"></a>

### DONE 3<sub>4</sub><sub>1</sub> Scaling Data Systems on the Cloud

-   Quick Review:
    -   early 2000's, things scaled out by adding replication SLAVES to a MASTER DB&#x2026;
    -   writes went to a single MASTER, reads went to SLAVES&#x2026;
    -   SLAVES could lose transactions, get out of sync..
-   RDBMS problems on the CLOUD..
    -   when small, OK
        -   single node for write data though CAN become overloaded with high write throughput.
    -   Nodes can be terminated or restarted by Cloud provider
        -   RDBMS are [C][P] systems (consistency guarantee, partition tolerant guarantee, no availability guarantee).  Hence, when MASTER node gets terminated, must need to re-elect a new MASTER node.  This creates DOWNTIME.
        -   due to growth of online platforms and explosion of numbers of users; a lot more data today being generated by online users of all kinds of services / apps.
-   consider PESSIMISTIC vs OPTOMISTIC design
    -   PESSIMISTIC design
        -   design w/ high [C]consistency, punish users 99.99% of the time
        -   higher consistency = higher latency (percieved slow)
        -   diminished user experience
    -   OPTIMISTIC design
        -   trust your datastore
        -   know your business AND your APPLICATION
            -   ask yourself, is X reliability that important?
        -   have a BACKUP plan
    -   Cassandra (C\*) Replication & Consistency
        -   famous implementation of DYNAMO protocol is CASSANDRA or C\*
        -   C\* WILL eventually converge on consistency, eventually
        -   EVENTUALLY is not..
            -   a day from now,
            -   a min from now,
            -   a second from  now,
        -   EVENTUALLY is usually just MILLISECONDS from NOW.


<a id="orgab8631c"></a>

### DONE 3<sub>4</sub><sub>2</sub> Eventual Consistency (Examples)

-   Example 1: Amazon
    -   item stock levels, is it really in stock or notions
        -   i.e. robotic inventory can't find it
        -   amazon cancels the order
    -   amazon contingency is to credit you 10% in future orders (customer dissatisfaction reward)
-   Example 2: Finance
    -   in theory, EVENTUAL consistency might not work..
    -   Banks:
        -   are actually the most consistent systems of all,
        -   what would happen if wrote a check for $1M and it wasn't covered,
        -   consistency plan: if check "bounces" the check, a fee is charged (punished for lack of consistency)
    -   hence, consistency CAN work in financial institutions
-   Why is ADOPTION of EVENTUAL CONSISTENCY so hard?
    -   ENGINEERS are stubborn; "1 + 1 = 2" now, not eventually =2
    -   middle management is scared,
        -   hard sell to convince to accept low consistency, stuck with high latency = poor user experienc
    -   have to engage product team, get them to buy in, have a contingency plan on how to compensate when rare moments of inconsistencty become visible to users
-   Example: Netflix / Amazon OUTAGE
    -   Netflix
        -   had an AMAZON outage in june 2012, data center went down..
        -   was running ORACLE..
        -   lost whole database
            -   had backups but spend 3-5 days restoring
        -   applications suffered, put up "maintenance pages"
        -   With e.g. CASSANDRA,
            -   could span MULTIPLE DATACENTERS,
            -   service would have DEGRADED, but still been RUNNING.


<a id="orgae9ff3e"></a>

### DONE 3<sub>4</sub><sub>3</sub> Deep Dive on DynamoDB

-   Definition: DYANAMO is name given to a set of TECHNIQUES that when taken together can form a highly AVAILABLE key-value structured storage system or distributed datastore.  It has properties of both databases and DHT's (distributed hash tables)
-   


<a id="org5090052"></a>

### DONE 3<sub>4</sub><sub>4</sub> Service Level Agreements


<a id="org8bd6015"></a>

### DONE 3<sub>4</sub><sub>5</sub> Dynamo Partition Algorithm


<a id="org0e53aa1"></a>

### DONE Reading Assignment: DYNAMO

The paper "Dynamo: Amazon's Highly Available Key-value Store" [dynamo], illustrates Amazon's solution to the problem of building an efficient, high availability, key-value storage system.

Key-value pairs are data types that include two pieces of data that include data values and associated key identifiers.  Key-value pairs are a critical component to distributed systems and their inner workings.  It's through the use of such data that multiple computers working together yet widely distributed can successfully share the workload of a single large task or set of tasks.  Control of such distributed computers requires reliable coordination, scheduling, and communication between such nodes.  Such control demands high availability of whatever data store such key-value pairs are saved in.

Traditionally, RDBS (relational database systems) have been the go-to tool for any problem requiring continuous read and write access to tables of data.  While key-value pairs are easily described as tables of data, the handling of them for use in distributed systems does not require most of the features that RDBS are more suited for.  For instance, key-value data stores do not require advanced queries, and management features found in RDBS's.  Additionally, key-value data stores require more flexibility in scaling up or down than what is typically found in RDBS's.

After reviewing data store alternatives to RDBS's such as Peer-to-Peer and Distributed File Systems, Amazon set out to design a key-value storage system that has the following characteristics:

1.  High Availability
2.  Provides and 'always on' experience to the client / user
3.  Easily or automatically scalable

The finished product, DynamoDB, is a database system built on the Dynamo principles of:

1.  Incremental Scalability
2.  Symmetry
3.  Decentralization
4.  Heterogeneity

DynamoDB has a number of unique features that allow it to meet these principles.  First, it sacrifices consistency for availability.  In doing so though it allows for inconsistencies that must be detected and resolved internally before return calls to the system.  Second, it distributes the workload of the multiple nodes via a distributed hash table in the form of a virtual ring.  Each computer occupies multiple 'spots' on the ring, creating the effect of virtual nodes and more evenly dispersing itself among its other peers in the ring.  Finally, access to the datastore is done as simply as possible through specialized get() and put() operations.  There is no specialized query language necessary to engage with the data store.  Additionally, this allows developers to build in awareness and even a degree of control of the key-value data stores into their applications at the design level.  While available, such design level awareness is not necessary to use DynamoDB though.  It should be noted that DynamoDB is only intended for trusted environments though.  DynamoDB does not focus on data integrity or security.  Amazon has successfully implemented DynamoDB and continues to test and refine the design.


<a id="orga7ed267"></a>

## TODO Homework #2


<a id="org22d52fc"></a>

# Module 4


<a id="orgb36aa3a"></a>

## Section 4<sub>1</sub>


<a id="org3ede6f5"></a>

### DONE 4<sub>1</sub><sub>1</sub> SQN and NoSQL

-   battle between RELATIONAL and NON-RELATIONAL databases,
-   primary goal is SCALABILITY, whole driving point of the CLOUD
-   if you scale the applications, users, and up time ; but don't scale your data / databases, then you've effectively stopped scaling,
-   STORAGE KINGDOM 1: NON RELATIONAL
    -   common structures: blobs, tables, queues
    -   no consistent INTERFACE
    -   tend to SCALE very well
    -   INTEGRITY is the domain of the developer / programmer (part of the trade off to acheive scalability, lose some transaction integrity)
-   STORAGE KINGDOM 2: RELATIONAL
    -   classic datbases such as oracle and ms sql server,
    -   provide high data integrity services
    -   support COMPLEX QUERIES involving joins of multiple tables
    -   harder to SCALE well, especially to multiple machines
    -   often contain LEGACY DATA from apps that need to move to the cloud.
-   EXAMPLE: Blog / SQl
    -   Relational:
        -   A TABLE for all your posts
            -   i.e. each post is a row in your table, rows have num id and text of post
        -   when want to read post, URL in that address basically says "give me post #x"
            -   query: "select all from POST TABLE where ID of POST is X
            -   response: post &#x2013;html renders text and send back to browser
        -   relational model common for blogs with COMMENTS
        -   COMMENTS table most like has same ID column as POSTS and COMMENTS data may be 'commentBody' or 'bodyText' etc.
        -   TABLE also have a column "post<sub>id</sub>", "post<sub>id</sub>" contains ID of blog post "COMMENT" relates to
        -   when reader comes buy, blog turns to database and ask for 2 things
            -   Query 1: SELECT ALL from POSTS TABLE where ID of POST is X
            -   Query 2: SELECT ALL from COMMENTS TABLE where ID of POST<sub>ID</sub> is X
                -   second query will return comments (if present), an array, that your blog will render to html and APPEND to the blog
-   EXAMPLE: Blog / NoSQL
    -   request comes in, blogging softwar turn around to db and says "please give me back this specific post and everything related to it", in this case a listing of related comments
    -   since not forece to be too uptight about having to define how the data is tructured beforehand, what if we atan to tag that post with an arbitrary number of categories?
        -   no problem, stick them on the same document and when the blog software says "gimme everytingon post 1" the tags, comments, and all other related info come back with it.
-   EXAMPLE: Grocery / NoSQL
    -   you can model the grocery list in a lot the same way  (as a piece of paper list)
        -   but say you figure out after a couple months that you want to keep track of how many loaves of bread you actually bought last year&#x2026;
        -   with non relational model you might literally have to go through every list and count each loaf individually where if you HAD modeled this in a relational way you could get back that cound almost instantly
-   SUMMARY: SQL vs NoSQL
    -   SQL Pros
        -   easy to use and setup
        -   universal, compatible with many tools
        -   good at high performance work loads
        -   good at structured data
    -   SQL Cons
        -   time consuming to understand design and structure of DB
        -   can be difficult to SCALE
    -   NoSQL Pros
        -   no investment to design models
        -   rapid development cycles
        -   gernally faster than SQL
        -   runs well on cloud
    -   NoSQL Cons
        -   unsuided for interconnected data (e.g. blog-posts ++ blog-comments)
        -   still maturing
        -   can have slower response times


<a id="org3089007"></a>

### DONE 4<sub>1</sub><sub>2</sub> Relational

-   Re CAP Theorm; SQL systems emphasize ACID
-   when you see [C]onsistency focus, think RELATIONAL db systems
-   RELATIONAL STORAGE 1:
    -   familiar db's such as oracle & ms sql.  made of tables containing typed columns (schema) and rows (data)
    -   used when relationships between data are NECESSARY and COMPLEX
    -   DB itself enforces INTEGRITY (e.g. can't delete customer when an order refers to it
-   RELATIONAL STORAGE 2:
    -   Have historically been the bottlenec of large systems
    -   Scale up well on a single node, often a large fast one, have more trouble scaling out (cloud) because of need for [C]onsistency
    -   but, most legacy data is in SQL / Relational storage, not going anywhere for time being
-   BACGROUND: Relational DB
    -   in rdbs, table is an organized set of data elements using a model of vertical columns, horizontal rows, & cells
    -   cells are where vertical columns and horizontal rows intersect
-   BACKGROUND: SQL Joins
    -   Joins clause combines records from two or more tables in a database
        -   creates a set that can be saved as a new table or used as is
        -   a Join is a meas for combining fields by using values COMMON to each


<a id="org8b7b30f"></a>

### DONE 4<sub>1</sub><sub>3</sub> Non Relational

-   definition:
    -   any of the more modern databases that essentially GIVE UP the ability to do JOINS in order to be able to avoid huge MONOLITH tables and scale more easily
        -   key-value (dynamo, redis)
        -   column-based (hbase, cassandra)
        -   document-based (mongodb)
    -   usually has more flexible SCHEMA (no rigid tables means no rigid NxM structure / size limitation)
        -   can build in new data / metadata / etc even after deployed without breaking anything
-   NoSQL in the CLOUD era
    -   datasets are just too BIG
    -   hundreds of thousands of visitors in short timee span, massive traffic increase
        -   rdbms developers try to cache read only front end to offload some traffic congestion
        -   memcache or integrate other CACHING mechanisms WITHIN the applications
            -   In-Memory indexes, distributing & replicating objecs over multiple nodes
        -   as datasets grow, simple memcache MySQL model starts to become problematic
-   NoSQL real world definition
    -   ingestion of data that has unknown and /or undeterminded structure
    -   relateve ease of scaling with increase of data
    -   ability ot analyze large volumes of data significantly quicker than trad SQL databases
    -   provides capabilities to derive VALUE from data (big and small)
-   NoSQL ( "NOT ONLY" SQL)
    -   INSERT only, no UPDATE/ DELETC
    -   no JOIN, thereby reducing query time
        -   involves denormalizing data (random scattering)
    -   lack of SQL support
    -   non-adherence to ACIC properties
    -   'not only sql'
    -   schema free
    -   embraces denormalization
    -   greater scaling capability
    -   simplicity of design
    -   storing objects that represent your domain
    -   great for unstructured or semi-structured data
-   Origins of NoSQL
    -   BigTable (google)
    -   Dynamo (amazon)
        -   distributed key-value data store
        -   gossip protocol
    -   CAP Theorem
        -   BASE vs ACID
-   SCALING, Horizontal and Vertical
    -   Scale-Up (vertical)
        -   more ram
        -   more cpu
        -   more HDD
    -   Scale-Out (horizontal)
        -   commodity hardware,
        -   more nodes
-   STRUCUTRE
    -   SQL
        -   relational, grids
        -   Analytical, (OLAP) branches
    -   NoSQL
        -   lists (key-value pairs)
        -   column families
        -   graphs
        -   documents (version control, historicity, inverted tree, descendents)
-   NoSQL DATABASES
    -   Column Stores
        -   Hbase, cassandra
        -   popular read/write tools
    -   Document Stores
        -   occasionally changing documents
        -   popular DB's couchbase, mongoDB
    -   Graph Databases
        -   usage: spatial data store
        -   popular: Neo4J, BigData
    -   Key-Value Pairs
        -   usage: frequently changing data, highly available
        -   popular: Riak, Redis
-   Making the move from relational to non relational&#x2026;
    -   relational uses keys like POST<sub>ID</sub> column in prev example..
    -   schema can constantly change between entries
-   DISADVANTAGES OF NoSQL
    -   LACK OF SUPPORT / MATURITY
        -   no SQL like unified language
        -   makes difficult to MIGRATE processes from old style to new
        -   some NoSQl are highly specialized and require more technical support
        -   companies fall into trap of open source software, more complex, little to no paid support
-   ADVANTAGES of NoSQL
    -   Flexibility
        -   easier to manage and more adept at dealing with newer data models
    -   Highly scalable at low cost
        -   many nosql db's are open source (free or affordable)
        -   nosql options allow for big data processing
        -   nosql CAN SCALE OUT vs only up
        -   nosql can scale out and spread out nodes, distributed compute load, storage load, etc
        -


<a id="org289d326"></a>

### DONE 4<sub>1</sub><sub>4</sub> NoSQL Flavors

-   Key-value, Document, Graph, In-Memory, & Search
-   Key-value Stores
    -   Redis, DynamoDB, Azure Table Storage, Riak,
    -   stores data in BUCKETS as a KEY and a VALUE
    -   each KEY must be UNIQUE
    -   values don't have a type, can contain anything
    -   think of it as a HASH TABLE
    -   very FAST write performance
    -   very FAST read IF you select based on KEY
    -   very slow if you need to search the VALUES instead of KEY
    -   works great for:
        -   flat data
        -   schemas that can't be modeled in rdbms
        -   consider .ini files, dictionary collections, hashstable collections, etc
-   Column Stores
    -   Cassandra, Hbase, hadoop, google bigtable,
    -   data stored in columns
    -   columns consist of key-value pair and timestamp
    -   columns grouped in "rows" or "column families"
    -   columns are grouped generally into tables
    -   NO JOINS PERMITTED
    -   WIDE COLUMNAR STORE
        -   no strick schema
        -   extremely fast performance
        -   benefits seen through decentralization and scalability
        -   no joins between tables
-   Graph
    -   Neo4J, JanusGraph, etc
    -   topology style, mathematical edges and vertices
    -   composed of nodes and relationships
    -   both can have key-value collections
    -   labels (tags) can be added
    -   IDEAL for when you have data DEFINED by RELATIONSHIPS
        -   friend tracking on facebook
        -   movie database
        -   searching for things like,
            -   firend of a friend..
            -   people who worked on a moveie with me who haven't worked with my friend
            -   shortest path between me and this person
    -   CAN also be very SLOW
-   Document store
    -   Azure DocumentDB, mongoDB, amazonDocumentDB, etc
    -   information stored as documents in JSON format, binary forms of JSON , and or XML
    -   Documents are collections of Key-Value pairs
    -   Documents reside in collections
    -   values can be strings, dates boolean, integers, even doucuments adn arrays
    -   very fast writing
    -   flexible indexing for fast value searching
    -   horizontal scaling
    -   schema
    -   great as an object store


<a id="org01dd6f6"></a>

### DONE 4<sub>1</sub><sub>5</sub> NoSQL Data Modeling

-   Role and Importance of Data Modeling
    -   have to really understand the nature of your data before designing storage system approach
-   NoSQL
    -   flexible schema. unlike sql schema (rigid)
        -   this flexibility facilitates mapping of documents to an entity or an object
        -   each document can match the data fields of the represented level, even if the data has substantial variation
            -   in practice, the documents in a collection share a similar structure
-   Challenges of DATA MODELING
    -   key challeng is balancing the NEEDS of the APPLICATION
        -   performance characteristics of the database engine
        -   data retrieval pattern
    -   when designing data models, always consider the application usage of the data (queries, updates, etc) as well as the inherent structure of the data itself.
-   Data Structure of NoSQL
    -   key decision in designing data models revolves around the STRUCUTRE of the DOCUMENTS and how the APPLICATION represents RELATIONSHIPS between DATA
        -   two tools that allow applications to REPRESENT RELATIONSHIPS: references and embedded documents
        -   <span class="underline">Embeded Documents</span>
            -   embedded documents capture relationships between data by storing related data in a single document structure.  NoSQL documents make it possible to embed document structures as sub-documents in a field or array within a document.
        -   when to use embedded documents,
            -   if you have 'contains' relationships between entities (one to one relationships)
            -   if you have one-to-many relationships between entities (one parent, many children example)
            -   Embedding provides better performance for read operations, as well as the ability to request and retrieve related data in a single database operation.
            -   Embedded data models make it possible to update related data in a single atomic write operation.
        -   <span class="underline">References</span>
            -   When to use:
                -   when using normalized data models
                    -   if embedding would result in duplication of data but not provide sufficient read performance advantage
                    -   to represent more complex many-to-many relationships
                    -   to model large hierarchical data sets
                -   refrence provide more flexibility than embedding.  however client side applications must issue follow-up queries to resolve the references.  in other words, normalized data models can require more round trips to the server.
        -   <span class="underline">Atomicity of Write Operations</span>
            -   write operations are atomic at teh DOCUMENT level and no single write operation can atomically affect more than one document or more than one collection
            -   a denormalized data model with embedded data combines all related data for a represented entity in a single document
                -   this facilitates atomic write operations since a single write operation can insert or update the data for an entity
            -   Normalizing the data would split teh data across multiple collectionand would requre mulitple rite operations that are not atomic collectively.
-   <span class="underline">Query Processing, NoSQL #1</span>
    -   NoSQL has some fundamental limitations that we need to be aware of..
        -   it calls for a more relaced data consistency model
        -   it provides primitive qurying and searching capability
    -   many contemporary NoSQL DB systems are based on the DTH distributed hash system model which provides a hashtable access semantics
        -   to access or modify ANY object data, the client is REQUIRED to supply the primary KEY of the object, then the DB will LOOKUP the object using an equality match to the supplied KEY.
-   <span class="underline">Query Processing, NoSQL #2</span>
    -   for example if we choose DHT to implement a customer DB, we can shoose the customer id as the key.  And then we can get/set/operate ON ANY CUSTOMER object if we know its id
        -   *cust<sub>data</sub> = DHT.get(cust<sub>id</sub>)*
        -   *DHT.set(cust<sub>id</sub>, modified<sub>cust</sub><sub>data</sub>)*
        -   *DHT.execute(cust<sub>id</sub>, func(cust){cust.add<sub>credit</sub>(200)})*
    -   in the real world, we may want to search data based on other attributes based on
        -   "greater / less than" relationship
        -   combine multiple search critera using a boolean expression
-   <span class="underline">Scatter/Gather Local Search</span>
    -   some of the NoSQL DB provide indexing and query processing mechanism within the local DB.  In this case, we can have the query processor broadcast the query to every node in the DHT where a local serch will be conducted with results send back to the query processor which aggregates into a single response.
    -


<a id="orge0cacfa"></a>

### DONE Quiz 4<sub>1</sub>


<a id="orga48bcc0"></a>

## Section 4<sub>2</sub>


<a id="org3388eb0"></a>

### DONE 4<sub>2</sub><sub>1</sub> Active Cloud Storage

-   PERSISTENT CLOUD STORAGE types (main categories provided by IaaS providers)
    -   Ephemeral
    -   Block Storage
    -   Object Storage
    -   Data Archiving
-   Storage Access
    -   by Blocks,
    -   by Files,
    -   by Objects
-   \_<sub>Ephemeral</sub> Storage\_\_
    -   effectively the 'whole instance' storage
    -   stores data used in the compute instance
    -   lifetime of the data is based on lifetime of the instance (like esxi vm management)
    -   IaaS providers provide and instance FAMILY that include HIGH storage instance
        -   very fast SSD-backed instance storage
        -   optimized for very high random I/O performance
        -   provide high IOPS at a low cost
        -   example, i2 family
    -   Use Cases:
        -   NoSQL databases like cassandra and mongodb
        -   scale out transactional databases
        -   data warehousing
        -   hadoop
        -   cluster file sytems
-   \_<sub>Block</sub> Storage\_\_
    -   block storage SERVICES allow user to create storage VOLUMES and ATTACH them to VMs
    -   once attached, user can create a FILE SYSTEM on these VOLUMES and run a database or use them in other ways
    -   block storage volume by most cloud vendors, tend to b placed in specific AVAILABILITY ZONES where they are automatically replicated to protect you from failure of a single component
    -   block storage volume TYPES offer durable SNAPSHOT capabilities and are designed for %99.999 availability
    -   block storage system manages the CREATION, ATTACHING, and DETACHING of the block devices to servers.
    -   appropriate for PERFORMANCE SENSITIVE scenarios
        -   i.e. database storage, expandable file systems,
    -   user can
        -   dynamically increase capacity
        -   tune performance
        -   change the type of live volumes with no downtime or performance impact.
    -   SNAPSHOT management:
        -   snapshots can be restored or used to create new block storage volumes
    -   CURRENT examples
        -   AWS EBS (elastic block storage)
        -   AWS EBS durability and availability
            -   without extr charge to customer, ebs volume data is replicated across multiple aws servers to prevent failure
            -   aws ebs volumes designed for annual failure rate (AFR) betwee  %0.1-%0.2


<a id="org4bcd119"></a>

### DONE 4<sub>2</sub><sub>2</sub> Long Term Storage

(cont from above)

-   <span class="underline">Object Storage</span>
    -   redundant, scalable, object storage using clusters of standardized servers capable of storing PETABYTES of data
    -   Object Storage is not a traditional file system, but rather a distributed storage system for static data such as virtual machine images, photo storage, email storage, backups and archives
        -   having no central brain or master point of control provides greater scalability, redundancy, and durability.
    -   Durability:
        -   object data written to multiple disk drives spread throughout the servers in the data center
            -   IaaS software responsible for ensuring data replication and integrity across cluster
        -   storage clusters scale horizontally simply by adding new servers
            -   if a server fails, IaaS system replicates it's content from other active nodes to new lcoation in the cluster.
            -   IaaS software uses software logic to ensure data replication and distribution across different devices, inexpensive commodity, hard drives, and servers can be used in lieu of more expensive equipment
            -   %99.999 durability adn scal bast tens of trillions of objects.
    -   compared to block storage

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">ephemeral</th>
<th scope="col" class="org-left">block</th>
<th scope="col" class="org-left">object</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">used to..</td>
<td class="org-left">run operating system</td>
<td class="org-left">add additional persistent</td>
<td class="org-left">store data, including vm</td>
</tr>


<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">and scratch space</td>
<td class="org-left">storage to a virtual</td>
<td class="org-left">images</td>
</tr>


<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">machine (vm)</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>

<tbody>
<tr>
<td class="org-left">accessed through ..</td>
<td class="org-left">a file system</td>
<td class="org-left">a block device that can</td>
<td class="org-left">REST API/vendor specific</td>
</tr>


<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">be partitioned, formatted,</td>
<td class="org-left">API</td>
</tr>


<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">and mounted</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>

<tbody>
<tr>
<td class="org-left">accessible frome..</td>
<td class="org-left">within a VM</td>
<td class="org-left">within a VM</td>
<td class="org-left">anywhere</td>
</tr>
</tbody>

<tbody>
<tr>
<td class="org-left">persists until ..</td>
<td class="org-left">VM is terminated</td>
<td class="org-left">deleted by user</td>
<td class="org-left">deleted by user</td>
</tr>
</tbody>

<tbody>
<tr>
<td class="org-left">sizing deter by..</td>
<td class="org-left">admin config, flavors</td>
<td class="org-left">user initial requ</td>
<td class="org-left">avail phys storage</td>
</tr>
</tbody>

<tbody>
<tr>
<td class="org-left">typical example..</td>
<td class="org-left">up to 1 TB</td>
<td class="org-left">several TB's</td>
<td class="org-left">10's of TB's of dataset</td>
</tr>
</tbody>
</table>

-   cont.
    -   AWS S3 Storage Class
        -   S3 standard
        -   S3 Intelligent Tiering
        -   S3 Standard Infrequent Access
        -   S3 One Zone-Infrequent access
        -   Amazon S3 Glacier
        -   Amazon S3 Glacier Deep Archive
-   <span class="underline">Data Archiving</span>
    -   IaaS provide a secure, durable, extremely low cost *cloud storage service* for data archiving and long term backup
    -   custoemrs can reliably store large or small amounts of data for less than 1 cent per cent per month
        -   much much cheaper than on site storage
    -   to keep costs low, data archiving technologies are optimized for infrequently accessed data where a retrieval time of several hours is suitable
    -   canb e very useful to decres the cost of storing data to S3 by moving the infrequent data to data archiving
-   <span class="underline">HUGE DATA TRANSFERS</span>
    -   transfering terabytes or petabytes of data from an existing data center to the cloud remains challenging
    -   all-in move to the cloud presents some issues..
    -
-   <span class="underline">Vendor offerings..</span>
    -   Block storage
        -   OpenStack: Cinder
        -   AWS: Elastic Block Storage (EBS)
    -   Object storage
        -   OpenStack: Swift
        -   AWS: S3
        -   Azure: Blob Storage
        -   Google: Google Cloud
    -   Data Archiving
        -   AWS: Glacier
    -   Huge Data Transfer
        -   AWS: SnowBall
        -   Azure: Import / Export


<a id="org19e6f56"></a>

### DONE Quiz 4<sub>2</sub>


<a id="org9a3a90e"></a>

## Section 4<sub>3</sub>


<a id="org8f74d4d"></a>

### DONE 4<sub>3</sub><sub>1</sub> Data Pipeline without Messaging System

-   Messages in the cloud..
    -   Messaging deals with SENDING data over the INTERNET to scale APPLICATION
    -   it is STATELESS (does not store, retain the data it sends)
    -   it is used to SYNCHRONIZE STATEFUL applications
    -   messaging carries the STATE but itself is STATELESS
-   Messaging Systems/Broker
    -   <span class="underline">Message Broker</span>: is an intermediary program module that TRANSLATES a MESSAGE from teh formal messaging protocol of the sender to the formal messaging protocol of the receiver.  example:
        -   Apache Kafka
        -   Apache ActiveMQ
        -   RabbitMQ
        -   Celery Task Queue, etc
    -   Messaging is an important piece of infrastrucutre for moving data between systems
    -   look at a data pipeline that doesn't have MESSAGING&#x2026;
        -   [pipeline without messaging] system starts hadoop for storage and data processing (will need data sent to it)
        -   sending initial data to seed hadoop is not a big deal..
        -   gets more complex though when multiple data streams / sources must also upload to hadoop concurrently over multiple channels
        -   each channel requires their own custom protocols and communication methods and moving data between these system becomes a full time job fore a team of developers..
        -   Eventually the application does less of what it was designed for and gets bogged down simply handling external requests, it becomes congested, traffic jams
        -


<a id="org56eef89"></a>

### DONE 4<sub>3</sub><sub>2</sub> Data Pipeline with Messaging System

-   cont. Now look at similar system WITH messaging..
    -   Kafka messaging bus example..
        -   all incoming data placed IN Kafka, all outgoing data is read FROM kafka
        -   kafka centralizes communication between producers of data and consumers of that data
    -   this is the PUB/SUB model (publishers and subscribers)
        -   MESSAGING consists of:
            -   *PRODUCER* are the ones that generate messages
            -   *CONSUMER* are the ones that recieve message from producer
            -   between the *CONSUMER* and *PRODUCER* is a message broker that is used to SYNCHRONIZE the messages between them
            -   *MESSAGE BROKER* performs synchronization of message with the help of queues which are used to add new messages or remove messages that are consumed
            -   Store and Forward: broker implements store and forward mechanism to sync messages
            -   queue in the BROKER will STORE messages until and unless some consumer CONSUMES those messages
            -   consumer consumes message -> processes it -> send back and acknowledgement indicating success
        -   DECOUPLING: producers and consumers are separated from each other and they involve decoupling to exchange messgaes with each other.  three types of decoupling
            -   *Logical Decoupling*: producers and consumers do not know anything about each other except routing info
            -   *Phyiscal Decoupling*: producers and consumers are on completely diff locations / networks / nodes
            -   *Temporal Decoupling*: messages consumed by consumer at later stage
        -   QUEUES and LOOSELY COUPLING:
            -   rather than controllers passing data directly to the next controller sequentially&#x2026;
            -   insert message queues between successive controllers, this will allow traffic to buffer and accumulate while not causing individual controllers to slow down or stall due to lack of incoming messages or inability to send out messages in order.


<a id="org37a7bfc"></a>

### DONE 4<sub>3</sub><sub>3</sub> Amazon SQS

-   close look at SQS messaging system example
    -   SQS = Simple Queue Service
        -   fast, scalable, and managed
    -   enables ASYNCHRONOUS MESSAGE-BASED COMMUNICAITON between DISTRIBUTED COMPONENTS of an application
    -   WHAT can sqs do..
        -   sqs can DECOUPLE (think like mechanical coupling) the components of a cloud application
        -   sqs can be used to transmit HIGH VOLUME of data WITHOUT LOSING MESSAGES and does not required other services to be available
        -   sqs can handle awareness of what services are currently up / down and knows how to handle messages accordingly
    -   HOW sqs does it (example)..
        -   producers &#x2013;> Master Queue &#x2013;> Master Worker..
            -   Master Worker to..
                -   S3 Queue
                    -   S3Q worker
                        -   S3 (consumer)
                -   ES Queue
                    -   ESQ worker
                        -   ES (consumer)
                -   RDS Queue
                    -   RDSQ worker
                        -   RDS (consumer)
    -   MAJOR features of SQS
        -   redundant infrastructure
        -   multiple writers and readers
        -   configurable setting per queue
        -   variable message size (up  to 256 kb)
        -   access control
        -   delay queue
    -   message DELETTION
        -   once consumed from the queue SQS does not delete the message..
            -   system is distributed: there's no guarantee that the components WILL receive the message,
            -   SQS does not delete the message, and instead, your consuming component must delete the message from the queue after receiving and processing it (so is SQS stateful?)
    -   message VISIBILITY TIMEOUT
        -   don't want other components of system receiving and processing message again,
        -   amazon SQS blocks them with a visibility timeout (de-duplication tool)
            -   is a period of time during which sqs prevents other consuming components from receiving and processing that same message.  Give the one initial consumer some time to process it and possibly delete it before letting it pass on to other subsequent consumer components.
    -   sqs message LIFECYCLE
        1.  componenet 1 sned message A to the queue
        2.  componenet 2 retreives message A from queue and visibility timeout starts
        3.  componenet 2 processes message A and then deletes it from the queue (itself) within the visibility timeout window.
    -   sqs DELAY QUEUES (different than message visibility timeout)
        -   allows for postponement of message delivery for set number of seconds
        -   any message sitting in delay queue is INVISIBLE to consumers for the duration of that period
        -   delay queues are SIMILAR to visibility time outs but ..
            -   difference is that for delay queues a message is hidden when IT IS FIRST ADDED to the queue, where for visibility timeouts the message is hidden ONLY AFTER A MESSAGE IS RETRIEVED from the queue by a consumer
            -


<a id="org91aad98"></a>

### DONE 4<sub>3</sub><sub>4</sub> AMQP and Exchanges

-   RabbitMQ / AMQP
    -   contains producers, consumers, EXCHANGES, QUEUES, BINDINGS, and a message broker
    -   EXCHANGES: function as putting the messages recieved from the producer into the RIGHT QUEUE present in the message broker
    -   QUEUEs: buffer up the messages until the consumer decides to fetch the messages
    -   BINDING: the link between EXCHANGES and QUEUES is called the BINDING
-   EXCHANGES, three types:
    1.  *Fan-Out Exchange*: in the fanout exchange, every message received from the producer is stored inall the queues present in the message broker (one-to-all)
    2.  *Direct Exchange*: the messages are stored in a queue when the routing key provided by the producer matches the binding key of the queue (one-to-one)
    3.  *Topic Exchange* involves the use of wildcard KEYS in order to store the messages to a PARTICULAR queue (one-to-many??) (like search operators)
-   NATURE OF QUEUES
    1.  *Transfer*: the transfer of message takes place into the ends of the queue, this ensures a consistent order of messages within the queue
    2.  *Browsing*: the messages stored in the queue are browsed from the side of the queue, this ensured a high amount of parallelism while accessing the messages from the queue and also ensures high throughput
    3.  *Synchronization*: whenever a copy of queue present in a message broker is created it is done using a particular order or using the sequence numbers similar to what TCP/IP does.
-   FAILURES, handling them
    -   failure to receive any ACK from broker the producer will try to send the same message again which leads to the duplication of messages.
    -   there is a potential for pocessing of duplicate message when consumer fails to ACK a processed message which is also know as redlivery
    -   even though the above is not ideal, at a minimum the system guarantees delivery of AT LEAST ONE MESSAGE


<a id="orgedcf551"></a>

### TODO Reading Assignment: Apache Kafka


<a id="orged740ac"></a>

## Section 4<sub>4</sub>


<a id="org86353d3"></a>

### TODO 4<sub>4</sub><sub>1</sub> Introduction to Kafka


<a id="orgc0245a8"></a>

### TODO 4<sub>4</sub><sub>2</sub> Deeper in Kafka


<a id="org984b56d"></a>

### TODO 4<sub>4</sub><sub>3</sub> Data Streaming Techniques


<a id="org5ff9a7f"></a>

## TODO Homework 3


<a id="org82d3985"></a>

## TODO Midterm


<a id="org982862b"></a>

# Module 5


<a id="org1a039c8"></a>

## TODO Section 5<sub>1</sub>


<a id="org45ce885"></a>

## TODO Section 5<sub>2</sub>


<a id="org7b59b15"></a>

## TODO Section 5<sub>3</sub>


<a id="orgc547af8"></a>

## TODO Homework 4


<a id="orgb0f40be"></a>

## TODO End of Course Eval

