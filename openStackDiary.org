#+TITLE: OpenStack Diary
#+AUTHOR:Silas Curfman
#+DESCRIPTION: Intro to Cloud, Spring 2023b
#+TEXT: Outline and Task list for report
#+SEQ_TODO: NEXT(n) TODO(t) WAITING(w) SOMEDAY(s) | DONE(d) CANCELLED(c)
#+SETUPFILE: ~/0xbadc0fee-standard-latex-export.org
#+OPTIONS: toc:t broken-links:mark

* HW 1
Set up OpenStack, see Mod 1 rubric
* Roadmap 
1. Environment Installation
   1. Security
   2. Host Networking
   3. NTP
   4. Package Archives
   5. SQL
   6. Message Queue
   7. Memcached
   8. Etcd
2. Projects Installation
   1. Keystone
   2. Glance
   3. Placement
   4. Nova
   5. Neutron
   6. Horizon
   7. Cinder

* Envrionment Installation Journal 
** Pre-install Tests / Notes
*** DONE Trial / Test VM's [6/6]
- [X] Install a HyperVisor (VMware / esxi)
- [X] Create multiple VM's for OpenStack Components
  - [X] CPU = 6 Cores
  - [X] RAM = 6 GB
  - [X] +HDD = 200 GB+
- [X] DO NOT USE AUTODEPLOY TOOLS
- [X] Take Screenshots for steps, attach here in journal
- [X] Collect information for use in publishing as a report
- [X] Create a references section for external resources, links

*** General Notes:
+ Use Yoga Install Instructions https://docs.openstack.org/swift/yoga/install/
+ Use minimal install version of OS (Ubuntu 20.0.4)
+ Use 64bit version of OS
+ Build Ea Host as it's own VM.  Can take snapshots, rollbacks, etc.
  (note that many vm's WILL have reduced performance as number of VMs increases)

*** Hypervisor Install Notes
+ Installed on HP ProLiant MicroServer, 4 TB, 32GB Ram
+ Balance min requirements per vm host comparing Ubuntu min req's and OpenStack min Req's, if room, install each service on sep host.
+ Build template vm and then replcate for each service, make edits as needed (#of nics, # of cores, etc)
+ Per yoga install... controller node: 1 core, 4GB ram, 5GB hdd
+ per yoga install... compute node:1 core, 2gb ram, 10GB hdd
+ Ubuntu lts server... 2 core, 4gb ram, 25gb hdd
+ template build.... 2 core, 6gb ram, 40 gb hdd, 2 NIC
------
*** Home Lab Config Notes:
+ Hypervisor (HVS): HP Proliant Microserver Gen10, 4tb, 32gb ram, 4 NICS,
+ Router (RTR): pfSense Firewall / Router, 4 NICS (WAN,LAN,OPT1,OTP2),
  + WAN : ISP
  + LAN: CLASS C 192.168.1.1/24
  + OPT1: CLASS A 10.0.0.1/24 DHCP4=FALSE
  + OPT2: CLASS C 203.0.113.1/24 DHCP4=TRUE
+ Physical Network
  + RTR igb0 <-> ISP
  + HVS igb0 <-> RTR igb1
  + HVS igb1  X
  + HVS igb2 <-> RTR igb2
  + HVS igb3 <-> RTR igb3
+ Virtual Network
  + vSwitch1 = management network <-> HVS igb2
  + vSwitch2 = provider network <-> HVS igb3
-----
*** DONE Environment Install Task List / YOGA / UBUNTU (1 VM per host method)
- [X] 5.1 _Security_ (Preconfigure VM's) [5/5]
  (specs from testing above, using HP Proliant Microserver & ESXI 7.0)
  - [X] CPU = 2 cores
  - [X] RAM = 4 GB
  - [X] HDD = 40 GB
  - [X] NICs = 2x
  - [X] 5x Instances
    - [X] 'controller'
    - [X] 'compute1'
    - [X] 'block1'
    - [X] 'object1'
    - [X] 'object2'
- [ ] _SNAPSHOTS_ (baremetal)
- [X] 5.2 _Host Networking_ [6/6]
  - [X] 'controller'[3/3]
    - [X] Management NIC : 10.0.0.11/24, gw:10.0.0.1
    - [X] Provider NIC  : via netplan, set dhcp4 & dhcp6 false, do not set static ip
    - [X] Edit etc/hosts: see pg 20 in pdf version of install docs
  - [X] 'compute1'[3/3]
    - [X] Management NIC : 10.0.0.31/24, gw:10.0.0.1
    - [X] Provider NIC : via netplan, set dhcp4 & dhcp6 false, do not set static ip
    - [X] Edit etc/hosts: see pg 22 in pdf version of install docs
  - [X] 'block1'[2/2]
    - [X] Management NIC : 10.0.0.41/24, gw:10.0.0.1
    - [X] Edit etc/hosts: see pg 23 in pdf version of install docs
  - [X] Confirm Connectivity: [7/7]
    - [X] from @controller, ping -c 4 docs.openstack.org == PASS
    - [X] from @controller, ping -c 4 compute1
    - [X] from @compute, ping -c 4 openstack.org
    - [X] from @compute, ping -c 4 controller
    - [X] repeat ping from @block1
    - [X] repeat ping from @object1
    - [X] repeat ping from @object2
  - [X] 'object1'
  - [X] 'object2'
- [X] 5.3 _NTP_ [3/3]
  - [X] Controller Node
  - [X] Other Nodes
  - [X] Verify
- [ ] _SNAPSHOTS_ (post-NTP, pre-package install)
- [X] 5.4 _Package Archives_ (repeat on all nodes) [1/1]
  - [X] Enable Repository / Ubuntu 20.04 / Yoga
- [X] _SQL_ (on controller) [3/3]
  - [X] Install Package
  - [X] Create & Edit config file
  - [X] Finalize
- [X] _Message Queue_ (on controller) [3/3]
  - [X] Install Package
  - [X] Add openstack user
  - [X] Permit config, write, & read access for user
- [X] _Memcached_ (on controller) [3/3]
  - [X] Install package (python3 version)
  - [X] edit config file
  - [X] Finalize (start service)
- [X] _Etcd_ (on controller) [2/2]
  - [X] Install Package
  - [X] edit config files
------
** Environment Install Footnotes 
+ From [[https://docs.openstack.org/install-guide/environment-networking.html]] :
#+BEGIN_QUOTE
The example architectures assume use of the following networks:
_Management on 10.0.0.0/24 with gateway 10.0.0.1_
This network requires a gateway to provide Internet access to all nodes for administrative purposes such as package installation, security updates, DNS, and NTP.
_Provider on 203.0.113.0/24 with gateway 203.0.113.1_
This network requires a gateway to provide Internet access to instances in your OpenStack environment.
You can modify these ranges and gateways to work with your particular network infrastructure.
Network interface names vary by distribution. Traditionally, interfaces use eth followed by a sequential number. To cover all variations, this guide refers to the first interface as the interface with the lowest number and the second interface as the interface with the highest number.
 Note
Ubuntu has changed the network interface naming concept. Refer Changing Network Interfaces name Ubuntu 16.04.
Unless you intend to use the exact configuration provided in this example architecture, you must modify the networks in this procedure to match your environment. Each node must resolve the other nodes by name in addition to IP address. _For example, the controller name must resolve to 10.0.0.11, the IP address of the management interface on the controller node._
#+END_QUOTE

+ <2023-03-30 Thu> NOTE: Installation Guide / Controller Node / Configure Network Interfaces...
  Documentation refers to old legacy method of network config using networkinterfaces.  Since Ubuntu 20.04 use /etc/netplan, not /etc/network/interfaces
#+NAME:Ubuntu Netplan Config
#+begin_src shell -n
$ cat /etc/netplan/00-installer-config.yaml
# This is the network config written by 'subiquity'
network:
  ethernets:
    ens160:
      addresses:
        - 10.0.0.11/24
      gateway4: 10.0.0.1
      nameservers:
              addresses: [8.8.8.8, 1.1.1.1]
    ens192:
      dhcp4: false
      dhcp6: false
  version: 2
#+end_src
- Be sure that both /etc/hosts and /etc/hostname have the corect names.
- If all is working, should be able to SSH to host (i.e. 10.0.0.11) and when logged in host name will display correctly in terminal

+ <2023-03-30 Thu> NOTE: Archive Enablement:
  using OpenStack Yoga for Ubuntu 20.04 LTS (server 64bit)
  - add-apt-repository cloud-archive:yoga

------
------
* Project(s) Installation Journal
** TODO Projects(s) Install Task List / YOGA / UBUNTU
*** DONE Keystone: Install [6/6]
- REF: Projects Install Doc / Yoga / Keystone ([[https:docs.openstack.org/keystone/yoga/doc-keystone.pdf][link]])
- TARGET(S): controller
- USER: root (either 'sudo -i'  or 'su -')
- [X] *Initialize SQL*
#+NAME: Database Prep
#+begin_src sh -n
  # mysql
  MariaDB > CREATE DATABASE keystone;
  MariaDB > GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'pwd123';
  MariaDB > GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'pwd123';  replace dbpass with password
#+end_src

- NOTE: A good test here would be to exit root (#), and as user ($) try to access the database.  If you get 1045 errors, that indicates an authentication problem and the rest of the process will fail until authentication is working.  When done testing from user, remember to return to root for remainder of process.  If the below does not produce a connection to SQL, stop and troubleshoot.
- [X] *Test SQL Connection*
  #+begin_src sh -n
    $ mysql -u keystone -p
    MariaDB [(none)]>
  #+end_src

- [X] *Instlal Kestone Package*
#+name: Install Keystone Package [2023-04-03 Mon] 
#+begin_src sh -n
  # apt install keystone
  # vi /etc/keystone/keystone.conf (make edits per docs)
  # su -s /bin/sh -c "keystone-manage db_sync" keystone
#+end_src
- [X] *Initialize Repositories*
#+name: Initialize Key Repositories
#+begin_src sh -n
  # keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
  # keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
#+end_src
- [X] *Bootstrap ID service*
#+name: Bootstrap the Identity Service [admin pwd = pwd123]
#+begin_src sh -n
  # keystone-manage bootstrap --bootstrap-password pwd123 --bootstrap-admin-url http://controller:5000/v3/ --bootstrap-internal-url http://controller:5000/v3/ --bootstrap-public-url http://controller:5000/v3/ --bootstrap-region-id RegionOne 
#+end_src
- [X] *Edit Env Variables*
#+name: Bootstrap Env Variables
#+begin_src sh -n
  $ export OS_USERNAME=admin
  $ export OS_PASSWORD=ADMIN_PASS
  $ export OS_PROJECT_NAME=admin
  $ export OS_USER_DOMAIN_NAME=Default
  $ export OS_PROJECT_DOMAIN_NAME=Default
  $ export OS_AUTH_URL=http://controller:5000/v3
  $ export OS_IDENTITY_API_VERSION=3
#+end_src

- NOTE: Before doing the above, do a '$ printenv' and look at the environment variables.  There should already be populated a number of OS_ (openstack) entries.  If not, it may mean that the bootstraping commands did not complete correctly.  This happened to me.  After backing up and going through the bootstrapping commands again I found 5 of the 7 above env variables already in print env.  After adding the missing two, the rest of the process ran correctly.

*** DONE Keystone: HW RESULTS [4/4]
- [X] *Confirm Token Assignment*

#+name: TOKEN
#+ATTR_LATEX: :options frame=single
#+begin_example sn -n
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2023-04-03T21:10:00+0000
         |
| id         | gAAAAABkKzKY1kcGmTmr2azLTezITAUGLjV7a_N_t90aZRQvr-lF7I0Oo3mq7sbeYBmKVEa_3rqiKuZipSpm_TMRKzObbF7yl_lup9-VkYmvl3_daPTAT5MDxrr_qHPqF0vl2TQMBZYA1we_-_RVnrUuHzPw9BR71TUXFiote79KFPSzxXkt7Es |
| project_id | af55244dfe134e73bb68d80af4842abb
         |
| user_id    | 483616691ea84ae3936b9cadd1725b4f
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
#+end_example

- [X] *Confirm demo (myuser) and admin users are created*
#+name:Create demo (myuser) and admin users
#+begin_example sh -n
$ openstack --os-auth-url http://controller:5000/v3 \
> --os-project-domain-name Default --os-user-domain-name Default \
> --os-project-name admin --os-username admin token issue
Password:
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2023-04-03T21:10:00+0000
         |
| id         | gAAAAABkKzKY1kcGmTmr2azLTezITAUGLjV7a_N_t90aZRQvr-lF7I0Oo3mq7sbeYBmKVEa_3rqiKuZipSpm_TMRKzObbF7yl_lup9-VkYmvl3_daPTAT5MDxrr_qHPqF0vl2TQMBZYA1we_-_RVnrUuHzPw9BR71TUXFiote79KFPSzxXkt7Es |
| project_id | af55244dfe134e73bb68d80af4842abb
         |
| user_id    | 483616691ea84ae3936b9cadd1725b4f
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

sgc@controller:~$ openstack --os-auth-url http://controller:5000/v3 \
> --os-project-domain-name Default --os-user-domain-name Default \
> --os-project-name myproject --os-username myuser token issue
Password:
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2023-04-03T21:14:47+0000
         |
| id         | gAAAAABkKzO3m0xEVmt5KXdpNRarHdbsQKu_R3Kvl_vsl_Qj4zLRd1sKbFmj6hLiImTpjfF2drCIqH0-NRIUfPKERlTJcj9k-1-Lw8W5b94eeDWs-m77VlXJLcpIjGiSehIM4TDhYqYuWmu4r_zs_OH5v3CllqhdtpV9HuMOku5jID5Ytf4YiPM |
| project_id | 9e2b1df7e13e4e90a1dfe3d12e96374e
         |
| user_id    | 2e7b44d196454070a7f6da6d66b61b5a
         |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
#+end_example

- [X] *Confirm user list can be retrieved*
#+name: RETRIEVE USER LIST
#+begin_example sh -n
MariaDB [keystone]> SELECT * FROM user
    -> ;
+----------------------------------+-------+---------+--------------------+---------------------+----------------+-----------+
| id                               | extra | enabled | default_project_id | created_at          | last_active_at | domain_id |
+----------------------------------+-------+---------+--------------------+---------------------+----------------+-----------+
| 2e7b44d196454070a7f6da6d66b61b5a | {}    |       1 | NULL               | 2023-04-03 20:05:06 | NULL           | default   |
| 483616691ea84ae3936b9cadd1725b4f | {}    |       1 | NULL               | 2023-04-03 19:55:11 | NULL           | default   |
+----------------------------------+-------+---------+--------------------+---------------------+----------------+-----------+
2 rows in set (0.000 sec)
#+end_example

- [X] *Confirm role list can be retrieved*
#+name:RETRIEVE ROLE LIST
#+begin_example sh -n
MariaDB [keystone]> SELECT * FROM role;
+----------------------------------+--------+-------+-----------+-------------+
| id                               | name   | extra | domain_id | description |
+----------------------------------+--------+-------+-----------+-------------+
| 0b25f16d85fa4fcdbbf560c8776b009c | admin  | {}    | <<null>>  | NULL        |
| 27490b2ef72343719edaad6ef2d3baa6 | myrole | {}    | <<null>>  | NULL        |
| 53a2975840ca44d1876980c8267a1c1b | member | {}    | <<null>>  | NULL        |
| 78965140ce3941b7806c809bdabe86e8 | reader | {}    | <<null>>  | NULL        |
+----------------------------------+--------+-------+-----------+-------------+
4 rows in set (0.001 sec)

MariaDB [keystone]>
#+end_example
------
*** DONE Glance: Install (on controller) [10/10]
- [X] *DB Configuration*
  #+begin_src sh -n
    # mysql
    MariaDB [(none)] CREATE DATABASE glance;
  #+end_src

- [X] Source the admin credentials (./os-scripts/) ~$ . admin-openrc~
- [X] Create the =glance= user
    #+begin_src sh -n
      $ cd ~/os-scripts
      $ openstack user create --domain default --password-prompt glance
      User Password:
      Repeat User Password:
      +---------------------+----------------------------------+
      | Field               | Value                            |
      +---------------------+----------------------------------+
      | domain_id           | default                          |
      | enabled             | True                             |
      | id                  | 5e99d020af48473da06c73a4ce96e50a |
      | name                | glance                           |
      | options             | {}                               |
      | password_expires_at | None                             |
      +---------------------+----------------------------------+
#+end_src
- [X] Add the admin role to the glance user and service project
  #+begin_src sh -n
  $ openstack role add --project service --user glance admin
  #+end_src
- [X] Create the glance service entry
  #+begin_src sh -n
  $ openstack service create --name glance \
  $ --description "OpenStack Image" image
  #+end_src
- [X] Create the Image Service API
  #+begin_src sh -n
  $ openstack endpoint create --region RegionOne \
  $ image public http://controller:9292
  #+end_src
- [X] Install glance packages
  #+begin_src sh -n
  # apt install glance
  #+end_src
- [X] Make edits to =/etc/glance/glance-api.conf=
  + Online documentation is does not match conf file installed via steps above.
  + [oslo_limit] section was missing but may not matter, not doing quota's
  + =use_keystone_quotas= is now =use_keystone_limits=, but no impact, left default false.
- [X] Populate Image service database and restart service
  #+begin_src sh -n
    # su -s /bin/sh -c "glance-manage db_sync" glance
    # service glance-api restart
  #+end_src
- [X] Verify Operation (see doc [[https://docs.openstack.org/glance/yoga/install/verify.html][link]])
*** DONE Glance: HW RESULTS [2/2]
- [X] HW Glance 1: Import Cirros OS Image
#+begin_example sh -n
  $ glance image-create --name "cirros" \
> --file cirros-0.4.0-x86_64-disk.img \
> --disk-format qcow2 --container-format bare \
> --visibility=public
+------------------+----------------------------------------------------------------------------------+
| Property         | Value                                                                            |
+------------------+----------------------------------------------------------------------------------+
| checksum         | 443b7623e27ecf03dc9e01ee93f67afe                                                 |
| container_format | bare                                                                             |
| created_at       | 2023-04-04T01:24:37Z                                                             |
| disk_format      | qcow2                                                                            |
| id               | 25c894f6-fe98-4da3-a8d9-89ef27508d46                                             |
| min_disk         | 0                                                                                |
| min_ram          | 0                                                                                |
| name             | cirros                                                                           |
| os_hash_algo     | sha512                                                                           |
| os_hash_value    | 6513f21e44aa3da349f248188a44bc304a3653a04122d8fb4535423c8e1d14cd6a153f735bb0982e |
|                  | 2161b5b5186106570c17a9e58b64dd39390617cd5a350f78                                 |
| os_hidden        | False                                                                            |
| owner            | af55244dfe134e73bb68d80af4842abb                                                 |
| protected        | False                                                                            |
| size             | 12716032                                                                         |
| status           | active                                                                           |
| tags             | []                                                                               |
| updated_at       | 2023-04-04T01:24:37Z                                                             |
| virtual_size     | 46137344                                                                         |
| visibility       | public                                                                           |
+------------------+----------------------------------------------------------------------------------+
sgc@controller:~$
#+end_example
- [X] HW Glance 2: Retrieve Image List
#+begin_example sh -n
  $ glance image-list
+--------------------------------------+--------+
| ID                                   | Name   |
+--------------------------------------+--------+
| 25c894f6-fe98-4da3-a8d9-89ef27508d46 | cirros |
+--------------------------------------+--------+
#+end_example
------
*** DONE Placement: Install [4/4]
- [X] Create Database [1/1]
  - [X] ... MySQL
      #+begin_src sh
    MariaDB [(none)]> CREATE DATABASE placement;
    Query OK, 1 row affected (0.000 sec)
    MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' \
        -> IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.000 sec)
    MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' \
        -> IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.001 sec)
    MariaDB [(none)]>
      #+end_src
- [X] Configure Access (placement password 'pwd123') [4/4]
  - [X] Create placement service user
    #+begin_src
  $ . admin-openrc
  $ openstack user create --domain default --password-prompt placement
  User Password:
  Repeat User Password:
  +---------------------+----------------------------------+
  | Field               | Value                            |
  +---------------------+----------------------------------+
  | domain_id           | default                          |
  | enabled             | True                             |
  | id                  | 40bc9dd8e8cc497482a2101cfb6fafb1 |
  | name                | placement                        |
  | options             | {}                               |
  | password_expires_at | None                             |
  +---------------------+----------------------------------+
  sgc@controller:~/os-scripts$
    #+end_src
  - [X] Add placement user to project with admin role
    #+begin_src
  $ openstack role add --project service --user placement admin
    #+end_src
  - [X] Create the placement API entry in the service catalog:
    #+begin_src
  $ openstack service create --name placement --description "Placement API" placement
  +-------------+----------------------------------+
  | Field       | Value                            |
  +-------------+----------------------------------+
  | description | Placement API                    |
  | enabled     | True                             |
  | id          | 37eca454070c402aa6b9851f5259d263 |
  | name        | placement                        |
  | type        | placement                        |
  +-------------+----------------------------------+
    #+end_src
  - [X] Create the Placement API service endpoints:
    #+begin_src
  $ openstack endpoint create --region RegionOne placement public http://controller:8778
  $ openstack endpoint create --region RegionOne placement internal http://controller:8778
  $ openstack endpoint create --region RegionOne placement admin http://controller:8778
    #+end_src
  - Output:
    #+begin_src
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | f566771fd27c4093a2f37af9b0aa876c |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 37eca454070c402aa6b9851f5259d263 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 6791ffa5a75544d3af6e0474b678f345 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 37eca454070c402aa6b9851f5259d263 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+

+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 58884a5d851141f5bea62d1af92ce83a |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 37eca454070c402aa6b9851f5259d263 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
    #+end_src
- [X] Install and Configure Components [3/3]
  - [X] Install placement and required database libraries (requires pip package)
    #+begin_src
# pip install openstack-placement pymysql
    #+end_src
  - [X] Create and edit /etc/placement/placement.conf
    #+begin_src
# mkdir /etc/placement
# touch /etc/placement/placement.conf
# vi /etc/placement/placement.conf
(... make edits per docs ...)
    #+end_src
    - *WARNING: IN ABOVE, YOU MUST REMOVE THE TEXT " # use noauth2 if not using keystone"*
  - [X] Populate the placement database
- [X] Finalize Installation
*** DONE Placement: HW RESULTS [1/1]
- [X] N/A, no placement resulst for HW required.
------
*** DONE Nova: Install [3/3]
NOTE: Nova installation will require steps done on both 'controller' and 'compute1'
NOTE: Nova installation will include the following services:
1. =nova-api= service
2. =nova-api-metadata= service
3. =nova-computer= service
4. =nova-scheduler= service
5. =nova-conductor= module
6. =nova-novncproxy= daemon
7. =nova-spicehtml5proxy= daemon
8. the queue (RammitMQ)
9. SQL database

**** DONE Controller Node: Prerequisites (doc 3.2.1.3) [8/8]
    1. [X] Create Database(s)
       #+begin_src
    MariaDB [(none)]> CREATE DATABASE nova_api;
    Query OK, 1 row affected (0.000 sec)

    MariaDB [(none)]> CREATE DATABASE nova;
    Query OK, 1 row affected (0.001 sec)

    MariaDB [(none)]> CREATE DATABASE nova_cell0;
    Query OK, 1 row affected (0.000 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.023 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.001 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.001 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.001 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.000 sec)

    MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'pwd123';
    Query OK, 0 rows affected (0.001 sec)

    MariaDB [(none)]> exit
       #+end_src
    2. [X] refresh admin credentials
    3. [X] Create Compute Service credentials
       =$ openstack user create --domain default --password-prompt nova=
       #+begin_src
    User Password:
    Repeat User Password:
    +---------------------+----------------------------------+
    | Field               | Value                            |
    +---------------------+----------------------------------+
    | domain_id           | default                          |
    | enabled             | True                             |
    | id                  | 5265a363fa7448d28fb3dbeb3e207f41 |
    | name                | nova                             |
    | options             | {}                               |
    | password_expires_at | None                             |
    +---------------------+----------------------------------+
       #+end_src
       =$ openstack role add --project service --user nova admin=
    4. [X] Create Compute API service endpoints
    5. [X] =openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1=
    6. [X] =openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1=
    7. [X] =openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1=
    8. OUTPUT:
       #+begin_src
  +--------------+----------------------------------+
  | Field        | Value                            |
  +--------------+----------------------------------+
  | enabled      | True                             |
  | id           | c5095a0dbe6042129e5c16fe7aea8a2b |
  | interface    | public                           |
  | region       | RegionOne                        |
  | region_id    | RegionOne                        |
  | service_id   | 5c50e287f96c40a69a6f17c7153631ff |
  | service_name | nova                             |
  | service_type | compute                          |
  | url          | http://controller:8774/v2.1      |
  +--------------+----------------------------------+

  +--------------+----------------------------------+
  | Field        | Value                            |
  +--------------+----------------------------------+
  | enabled      | True                             |
  | id           | 037ca65f5b494c6691037e0ecde56810 |
  | interface    | internal                         |
  | region       | RegionOne                        |
  | region_id    | RegionOne                        |
  | service_id   | 5c50e287f96c40a69a6f17c7153631ff |
  | service_name | nova                             |
  | service_type | compute                          |
  | url          | http://controller:8774/v2.1      |
  +--------------+----------------------------------+

  +--------------+----------------------------------+
  | Field        | Value                            |
  +--------------+----------------------------------+
  | enabled      | True                             |
  | id           | de4fc9eabb394888af11d21316106a15 |
  | interface    | admin                            |
  | region       | RegionOne                        |
  | region_id    | RegionOne                        |
  | service_id   | 5c50e287f96c40a69a6f17c7153631ff |
  | service_name | nova                             |
  | service_type | compute                          |
  | url          | http://controller:8774/v2.1      |
  +--------------+----------------------------------+
       #+end_src
    9. [X] Install Placement Service (completed prior, see previous section)
**** DONE Controller Node: Install & Configure Components (doc 3.2.1.3 cont) [8/8]
    1. [X] Install packages
       =# apt install nova-api nova-conductor nova-novncproxy nova-scheduler=
    2. [X] Edit /etc/nova/nova.conf
       + confusing step on [neutron] edits to nova.conf, duplicated in neutron setupd
    3. [X] Populate ~nova-api~ database
       =# su-s /bin/sh -c "nova-manage api_db sync" nova=
    4. [X] Register cell0 database
       =# su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova=
    5. [X] create ~cell1~ cell
       =# su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell --verbose" nova=
    6. [X] Populate the ~nova~ database
       =# su -s /bin/sh -c "nova-manage db sync" nova=
    7. [X] Verify nova ~cell0~ and ~cell1~ registered correctly
       =#su -s /bin/sh -c "nova-manage cell_v2 list_cells" nova=
    8. [X] Finalize and restart services
       #+begin_src
    # service nova-api restart
    # service nova-scheduler restart
    # service nova-conductor restart
    # service nova-novncproxy restart
       #+end_src
**** DONE Install and Configure Compute Node (doc 3.2.1.4) [3/3]
*NOTE: DO THESE STEPS ON THE COMPUTE NODE, NOT THE CONTROLLER NODE*
*NOTE: to sync admin credential scripts, use SCP to copy ~/os-scripts to target node*
1. [X] Install packages
2. [X] Make edits to /etc/nova/nova.conf (on compute node)
3. [X] Finalize
*** TODO Nova: HW RESULTS [0/3]
- [ ] Screenshot: Retrieve a VM list
- [ ] Screenshot: Create a VM
- [ ] Screenshot: Login VM
------ 
*** DONE Neutron: Install [3/3]
**** DONE Verifiy connectivity [4/4]
- [X] controller to compute1
  #+begin_example
sgc@controller:~$ ping -c 2 compute1
PING compute1 (10.0.0.31) 56(84) bytes of data.
64 bytes from compute1 (10.0.0.31): icmp_seq=1 ttl=64 time=0.121 ms
64 bytes from compute1 (10.0.0.31): icmp_seq=2 ttl=64 time=0.251 ms

--- compute1 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1026ms
rtt min/avg/max/mdev = 0.121/0.186/0.251/0.065 ms
  #+end_example
- [X] controller to WAN
#+begin_example
sgc@controller:~$ ping -c 2 www.google.com
PING www.google.com (142.250.217.68) 56(84) bytes of data.
64 bytes from sea09s29-in-f4.1e100.net (142.250.217.68): icmp_seq=1 ttl=56 time=17.8 ms
64 bytes from sea09s29-in-f4.1e100.net (142.250.217.68): icmp_seq=2 ttl=56 time=17.3 ms

--- www.google.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 17.270/17.544/17.818/0.274 ms
#+end_example
- [X] compute1 to controller
#+begin_example
sgc@compute1:~$ ping -c 2 controller
PING controller (10.0.0.11) 56(84) bytes of data.
64 bytes from controller (10.0.0.11): icmp_seq=1 ttl=64 time=0.295 ms
64 bytes from controller (10.0.0.11): icmp_seq=2 ttl=64 time=0.353 ms

--- controller ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1003ms
rtt min/avg/max/mdev = 0.295/0.324/0.353/0.029 ms
#+end_example
- [X] compute1 to WAN
#+begin_example
sgc@compute1:~$ ping -c 2 www.google.com
PING www.google.com (142.250.69.196) 56(84) bytes of data.
64 bytes from sea30s08-in-f4.1e100.net (142.250.69.196): icmp_seq=1 ttl=56 time=16.6 ms
64 bytes from sea30s08-in-f4.1e100.net (142.250.69.196): icmp_seq=2 ttl=56 time=16.2 ms

--- www.google.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 16.179/16.399/16.620/0.220 ms
sgc@compute1:~$
#+end_example
**** DONE Install and configure controller node [5/5]
- [X] Prerequisites (6.2.1) [4/4]
  - [X] Create Database
    - =$ mysql -u root -p=
    - =MariaDB [(none)] CREATE DATABASE neutron;=
    - =MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \=
      =IDENTIFIED BY 'NEUTRON_DBPASS';=
    - =MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \=
      =IDENTIFIED BY 'NEUTRON_DBPASS';=
  - [X] Re-source admin credentials
    - =$. ./os-scripts/admin-openrc=
  - [X] Create service credentials
    - Create neutron user
      =$ openstack user create --domain default --password-prompt neutron=
    - Add admin role to neutron user
      =$ openstack role add --project service --user neutron admin=
    - Create Neutron service entity
      =$ openstack service create --name neutron \ =
      =--description "OpenStack Networking" network=
  - [X] Create Networking service API Endpoints
    - $ =openstack endpoint create --region RegionOne \=
        =network public http://controller:9696=
    - $ =openstack endpoint create --region RegionOne \=
        =network internal http://controller:9696=
    - $ =openstack endpoint create --region RegionOne \=
        =network admin http://controller:9696=
- [X] Configure Networking Options (6.2.2) [6/6]
  - Selected Provider Network, see environment notes on homelab
  - [X] Install components
    #+begin_src sh
      # apt install neutron-server neutron-plugin-ml2 \
      neutron-linuxbridge-agent neutron-dhcp-agent \
      neutron-metadata-agent
    #+end_src
  - [X] Configure server component
  - [X] Configure modular layer 2 plug-in
  - [X] Configure linux bridge agent
  - [X] Configure DHCP agent
  - [X] Configure Metadata agent (6.2.3)
- [X] Create provider network (not possilbe until neutron is finished?? why in docs?) [3/3]
  - [X] source credentials
  - [X] create the network (not possilbe until neutron install is finished??)
    + OUTPUT:
      #+begin_src sh
        sgc@controller:~$ openstack network create  --share --external \
        >   --provider-physical-network provider \
        >   --provider-network-type flat provider
        +---------------------------+--------------------------------------+
        | Field                     | Value                                |
        +---------------------------+--------------------------------------+
        | admin_state_up            | UP                                   |
        | availability_zone_hints   |                                      |
        | availability_zones        |                                      |
        | created_at                | 2023-04-08T20:42:50Z                 |
        | description               |                                      |
        | dns_domain                | None                                 |
        | id                        | 5c3c019c-274b-4c72-8d19-7f1f9b99d4d4 |
        | ipv4_address_scope        | None                                 |
        | ipv6_address_scope        | None                                 |
        | is_default                | None                                 |
        | is_vlan_transparent       | None                                 |
        | mtu                       | 1500                                 |
        | name                      | provider                             |
        | port_security_enabled     | True                                 |
        | project_id                | af55244dfe134e73bb68d80af4842abb     |
        | provider:network_type     | flat                                 |
        | provider:physical_network | provider                             |
        | provider:segmentation_id  | None                                 |
        | qos_policy_id             | None                                 |
        | revision_number           | 1                                    |
        | router:external           | External                             |
        | segments                  | None                                 |
        | shared                    | True                                 |
        | status                    | ACTIVE                               |
        | subnets                   |                                      |
        | tags                      |                                      |
        | updated_at                | 2023-04-08T20:42:50Z                 |
        +---------------------------+--------------------------------------+
        sgc@controller:~$
      #+end_src
  - [X] create a subnet on the network
    + OUTPUT:
      #+begin_src sh
        
      #+end_src
- [X] Configure compute service to use the networking service (6.2.4)
- [X] Finalize (6.2.5)
**** DONE Install and configure compute node [5/5]
- [X] Install the components (6.3.1)
  =# apt install neutron-linuxbridge-agent=
- [X] Configure the common component (6.3.2)
- [X] Configure networking options (6.3.3)
- [X] Configure the compute service to use the networking service (6.3.4)
- [X] Finalize (6.3.5)
*** TODO Neutron: HW RESULTS [0/1]
- [ ] Screenshot: Create a Network
  
------
*** DONE Horizon: Install [3/3]
- [X] Install packages
  =# apt install openstack-dashboard=
- [X] Edit /etc/openstack-dashboard/local_settings.py
- [X] Append to /etc/apache2/conf-available/openstack-dashboard.conf
- FOOTNOTE:
  After following the installation instructions, I could not access the horizon dashboard via a browser.  I was testing the web portal from a physical laptop on the same network as the horizon dashboard.  Every time I tried to access it I received HTTP 500 errors.  Trying to access http://controller/ yielded an Apache2 test page.  Trying to access http://controller/horizon/ failed.  The error logs in /var/log/apache2/error.log indicated a problem with the code used to disable layer-3 networking in the /openstack/local_settings.py file.  I removed the code added in order to disable layer-3 networking and the horizon dashboard then loaded correctly.
*** DONE Horizon: HW RESULTS [2/2]
- [X] Login in with proper account (screenshot)
  [[./img/service060horizon(3).png]]
- [X] Retrieve service information (screenshot)
[[./img/service060horizon(2)-small.png]]
------
*** TODO Cinder: Install [0/2]
- [ ] Configure 'controller' node [0/4]
  - [ ] Prerequisites [0/4]
    - [ ] Create database & grand access
    - [ ] refresh admin credentials
    - [ ] create service credentials
    - [ ] create service api endpoints
  - [ ] Install & Configure Components [0/0]
    1. Install Package(s)
      =#$ apt install cinder-api cinder-scheduler= 
    2. Edit /etc/cinder/cinder.conf
       1. [database]
       2. [DEFAULT]... RabbitMQ
       3. [DEFAULT]... Keystone
       4. [DEFAULT]... my_ip
    3. Set [oslo_concurrency] lock path
    4. Poplulate the Block Storage database:
  - [ ] Configure Compute service to use Block Storage
    - Edit /etc/nova/nova.conf [cinder]...
      =os_region_name = RegionOne=
  - [ ] Finalize Installation
    - =# service nova-api restart=
    - =# service cinder-scheduler restart=
    - =# service apache2 restart=
- [ ] Configure 'block1' node [0/0]
*** TODO Cinder: HW RESULTS [0/2]
- [ ] Screenshot: Create a volume
  
- [ ] Screenshot: Retrieve a volume list
  
------
*** TODO Swift: Install [3/5]
- [X] Install and Configure Controller Node (5.9.3)
  - [X] Prerequisites
    - [X] 1. Source admin credentials
      =# ./os-scripts/admin-openrc=
    - [X] 2. Create identity service credentials
    - [X] 3. Create object storage api endpoints
  - [X] Install and configure components
    - [X] 1. Install Package(s) (MUST BY PYTHON3!)
      #+begin_src sh
# apt-get install swift swift-proxy python3-swiftclient python3-keystoneclient python3-keystonemiddleware memcached
      #+end_src
    - [X] 2. Create /etc/swift directory
    - [X] 3. Obtain proxy service config file from object storage repository
      #+begin_src sh
# curl -o /etc/swift/proxy-server.conf https://opendev.org/openstack/swift/raw/branch/master/etc/proxy-server.conf-sample
      #+end_src
    - [X] 4. Edit /etc/swift/proxy-server.conf
      + [DEFAULT]
        #+begin_export sh
bind_port = 8080
user = swift
swift_dir = /etc/swift
        #+end_export
      + [pipeline:main]
        #+begin_src sh
pipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server
        #+end_src
      + [app:proxy-server] 
        #+begin_src sh
use = egg:swift#proxy
...
account_autocreate = True
        #+end_src
      + [filter:keystoneauth]
        #+begin_src sh
use = egg:swift#keystoneauth
...
operator_roles = admin,user          
        #+end_src
      + [filter:authtoken]
        #+begin_src sh
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
...
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_id = default
user_domain_id = default
project_name = service
username = swift
password = SWIFT_PASS
delay_auth_decision = True
#+end_src
      + [filter:cache]
        #+begin_src sh
use = egg:swift#memcache
...
memcache_servers = controller:11211
#+end_src
- [X] Install and Configure Storage Node(s) (5.9.4)
  (repeat steps for each storage node)
  - [X] Prerequisites [8/8] 
    - [X] 1. Install packages
      =# apt-get install xfsprogs rsync=
    - [X] 2. format devices
      =# mkfs.xfs /dev/sdb=
      =# mkfs.xfs /dev/sdc=
    - [X] 3. create mount points
      =# mkdir -p /srv/node/sdb=
      =# mkdir -p /srv/node/sdc=
    - [X] 4. parse UUID
      =# blkid=
    - [X] 5. edit /etc/fstab
      #+begin_src sh
        UUID="<UUID-from-output-above>" /srv/node/sdb xfs noatime 0 2
UUID="<UUID-from-output-above>" /srv/node/sdc xfs noatime 0 2
      #+end_src
    - [X] 6. mount devices
      =# mount /srv/node/sdb=
      =# mount /srv/node/sdc=
    - [X] 7. edit /etc/rsyncd.conf
      #+begin_src sh
        uid = swift
gid = swift
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 10.0.0.51

[account]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/account.lock

[container]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/container.lock

[object]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/object.lock
      #+end_src
    - [X] 8. start rsync service
      =# service rsync start=
  - [X] Install & Configure Components [7/7]
    - [X] 1. Install packages
      =# apt-get install swift swift-account swift-container swift-object=
    - [X] 2. Obtain accounting, container, & object service configs from repository
      #+begin_src sh
        # curl -o /etc/swift/account-server.conf https://opendev.org/openstack/swift/raw/branch/master/etc/account-server.conf-sample
        # curl -o /etc/swift/container-server.conf https://opendev.org/openstack/swift/raw/branch/master/etc/container-server.conf-sample
        # curl -o /etc/swift/object-server.conf https://opendev.org/openstack/swift/raw/branch/master/etc/object-server.conf-sample
      #+end_src
    - [X] 3. Edit /etc/swift/account-server.conf
      + [DEFAULT]
        #+begin_src sh
          ...
bind_ip = 10.0.0.51
bind_port = 6201
user = swift
swift_dir = /etc/swift
devices = /srv/node
mount_check = True
        #+end_src
      + [pipeline:main]
        #+begin_src sh
          pipeline = healthcheck recon container-server
        #+end_src
      + [filter:recon]
        #+begin_src sh
          use = egg:swift#recon
...
recon_cache_path = /var/cache/swift
        #+end_src
    - [X] 4. Edit /etc/swift/container-server.conf
      - [X] DEFAULT
      - [X] pipeline:main
      - [X] filter:recon
    - [X] 5. Edit /etc/swift/object-server.conf
      - [X] DEFAULT
      - [X] pipeline:main
      - [X] filter:recon
    - [X] 6. Ensure ownership of mount point structure
    - [X] 7. Create ~recon~ directory and assign ownership      
- [X] Create and Distribute Initial Rings (5.9.5) [4/4]
  - [X] Create account ring
    - [X] Create base account.builder
    - [X] add each storage node to ring
    - [X] verify ring contents
    - [X] rebalance ring
  - [X] Create container ring
    - [X] Create base account.builder
    - [X] add each storage node to ring
    - [X] verify ring contents
    - [X] rebalance ring
  - [X] Create object ring
    - [X] Create base account.builder
    - [X] add each storage node to ring
    - [X] verify ring contents
    - [X] rebalance ring
  - [X] Distribute ring files
- [ ] Finalize Installation (5.9.6)
- [ ] Installation Screenshots
*** TODO Swift: HW RESULTS [/]
